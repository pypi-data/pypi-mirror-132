Metadata-Version: 2.1
Name: gym-recorder
Version: 0.0.3
Summary: A simple and ubiquitous transition recorder wrapper for Gym Environments to facilitate offline reinforcement learning dataset manufacturing.
Home-page: https://github.com/bryanoliveira/gym-recorder
Author: Bryan L M Oliveira
Author-email: bryanlmoliveira@gmail.com
License: UNKNOWN
Project-URL: Bug Tracker, https://github.com/bryanoliveira/gym-recorder/issues
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: POSIX :: Linux
Classifier: Operating System :: Microsoft :: Windows
Classifier: Operating System :: MacOS
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Utilities
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: gym (>=0.19.0)
Requires-Dist: json-tricks (>=3.15.5<4.0.0)
Requires-Dist: jsonlines (>=3.0.0<4.0.0)
Requires-Dist: lz4 (>=3.1.10<4.0.0)
Requires-Dist: numpy (>=1.21.2<2.0.0)
Requires-Dist: ray[rllib] (>=1.4.0<1.5.0)

# Transition Recorder Wrapper for Gym Environments

A simple and ubiquitous transition recorder wrapper for Gym Environments to facilitate offline Reinforcement Learning (RL) dataset manufacturing. Transitions (observations, actions, rewards, dones & infos) and episodes (set of transitions) are buffered with LZ4 compression and each episode is saved as a JSON line (.jsonl). Output files may be further processed to be compatible with offline RL libraries like [Ray RLlib](https://docs.ray.io/en/master/rllib/index.html) (see Usage).

## Requirements

- Python >= 3.6
- Pypi packages: `pip install -r requirements.txt`

## Usage

Simply import & wrap your Gym environment:

```python
import gym
from gym_recorder import TransitionRecorderWrapper  # import the wrapper

env = gym.make("CartPole-v1")
env = TransitionRecorderWrapper(env)  # wrap your environment
env.reset()

# Use your environment as you would
while True:
    env.render()
    action = env.action_space.sample()
    obs, reward, done, info = env.step(action)
    if done:
        env.reset()
```

You may also use the `save_folder` option to customize where the transitions are saved, `min_transitions_per_file` to customize the output file size, and disable compression with the `compress` option.

### Conversion

The generated `.jsonl` files may be further processed to be used by offline RL libraries like [Ray RLlib](https://docs.ray.io/en/master/rllib/index.html). To convert a `.jsonl` dataset generated by the wrapper to a [RLlib offline dataset](https://docs.ray.io/en/master/rllib-offline.html) you may run the following command:

`python -m gym_recorder.converters.ray -i data/raw -o data/ray`

More options can be found with `python -m gym_recorder.converters.ray --help`.


