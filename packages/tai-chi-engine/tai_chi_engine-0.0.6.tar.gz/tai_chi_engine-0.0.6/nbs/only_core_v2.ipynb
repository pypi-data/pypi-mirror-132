{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tai-Chi core engine\n",
    "> What library should we be?\n",
    "This proposal, is more of a branding proposal, targeting people who's going to play with AI, from various back grounds.\n",
    "* That means, we're going to talk about how people view this library, how they think of ```pip install -Uqq unpackai``` like if I have dandroff recengtly and my mind just jump right into the headshoulders.\n",
    "* For ML, currently, the **jump** is about the following, this is not a throught marketing research, just quick examples from a deep learning practitioner:\n",
    "    * Try free structure quickly, do experiments: pytorch\n",
    "    * Goes to production, run model on edge devices, Tensorflow\n",
    "    * Play with GPU accelerated tensor calculation: Jax\n",
    "    * Play with tf but in simpler layer sense: Keras\n",
    "    * Transformer in clean code: Huggingface\n",
    "    * Visualize things with interactive features: Plotly\n",
    "    * Deploy model prototype: streamlit\n",
    "* Surely you think I fail to mention ```fastai```, this is where the **branding goes wrong**, fastai library is bounded tightly with the education. It's considered a good creation along side its famous course, after the education. Its product feature has many limitation: docs too brief, not supporting multi-device training, very limited numbers of callbacks went beyond Jeremy H's own teaching.\n",
    "* Most important of all, ```fastai``` isn't enjoyable to use, **it's just packing many things mentioned in the course**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we shouldn't be\n",
    "I know the course is life changing for me and I feel very grateful. But let's not be their library.\n",
    "\n",
    "### The pipeline wrapping plan\n",
    "It all started from a notebook, quite like a template notebook we have for the course. A notebook that achieves the data processing, model building, interpretation for a specific DL task.\n",
    "\n",
    "Then came the packaging part, we wrap **dozens of lines of codes**, which scares our kind students, into simple functions, or class.\n",
    "\n",
    "The wrapped functions are simple to use, to look at, it was executed in 1 line mostly. So friendly to our innocent students.\n",
    "\n",
    "This is what a python library is about, right? Wrap things into functions which can be further wraped into even less lines.\n",
    "\n",
    "It's nothing wrong about this approach at first. Some DL task, if need be, can be shrank into **less than 10 lines of codes.**\n",
    "* The 1st line load the data, \n",
    "* the 2nd line set how to transform data, \n",
    "* the 3rd line build/load the model, \n",
    "* the 4th line trained model.\n",
    "* the 5th line interpret the model in various ways\n",
    "\n",
    "Well the above do look like a decent **structure** to start with, then we pave out the tasks, different contributors take different tasks, can be developed in parallel, and we can have the agile/crum/kanban fun to track our progress!\n",
    "\n",
    "Even if we do this, we could build a useful product, no less.\n",
    "\n",
    "#### Bad side about pipeline wrapping plan\n",
    "So so many libraries are doing the same, from awesome people even. They usually end up to the following:\n",
    "* It's a mess of functions, among them many good functions but a mess. It ends up a branding disaster. (**There is no way to answer: what can you library do, in a slogan**)\n",
    "* A model zoo for a specific domain.\n",
    "* Wraping things up means less and less involvement from the user. The user will spend very little time play with the functions, and each function usually achieve very specific task. Actually I do believe there is a equilibrium like:\n",
    "$\\large{UserPlayHours = a * Task Transferability}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The salvation plan is somehow simpler at how we perceive the library:\n",
    "* A library that allows you experiment AI/DL for various tasks\n",
    "\n",
    "**BUT!!!**\n",
    "* Many module with in the pipeline should be dropdown-list/checkbox **Choosable**.\n",
    "* The **level of detail** we let them to play and choose, is the **level of the difficulty** we want them to enjoy\n",
    "\n",
    "### What is level of detail ?\n",
    "Level of details is the level of fuss we want user to focus on, this is the exact part fastai library got **WRONG**, which will explain most of our struggle so far:\n",
    "* It offers smooth/ easy pipelines, for newbies and business people even.\n",
    "* Any amount of reconfigure, is usually way too complicated for such audience\n",
    "* There is a **GAP** between the 2 points above, hence no room for playing\n",
    "\n",
    "#### Keras Example \n",
    "I started my AI journey with Keras, and I love keras by that time, because:\n",
    "* Keras plays with **layers**(eg. Linear, Convolution), its most strenth is at astracting details beneath this level, and let users play with layers. \n",
    "* I spent lots of time, having fun playing with layers\n",
    "* Aside from the things I have to redesign layer, I can deploy almost all kinds of models mentioned in any DL paper (ùëàùë†ùëíùëüùëÉùëôùëéùë¶ùêªùëúùë¢ùëüùë†=ùëé‚àóùëáùëéùë†ùëòùëáùëüùëéùëõùë†ùëìùëíùëüùëéùëèùëñùëôùëñùë°ùë¶)\n",
    "\n",
    "#### Pytorch lightning example\n",
    "Well I moved on to the career team. I have to deal with layer level, I have to deal with different data/forward pipeline. PL is a good library because:\n",
    "* It allows me play with the things I mentioned, but save my energy on things like looping, logging, multidevice training detail etc.\n",
    "* If you see a training notebook built by PL, you'll see very little lines around training template.\n",
    "* You'll find about a lots of lines on the specifications you intend to be different.\n",
    "\n",
    ">The branding image of the examples are simple:\n",
    "* Keras: play TensorFlow in a concept of layers\n",
    "* Pytorch-Lightning: writting less template code\n",
    "\n",
    "#### Unpackai Example\n",
    "For our lib, I intend for them to focus on, exactly the same range of things we want people to learn:\n",
    "* choose the columns they intend to use, in what way\n",
    "* choose the data transformations\n",
    "* choose the loss, the model structure to use (not keras.layer, not nn.module)\n",
    "* hit run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of such example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "versions\n",
    "```json\n",
    "{\n",
    "  \"torch\": \"1.7.1\",\n",
    "  \"pytorch-lightning\": \"1.3.8\",\n",
    "  \"unpackai\": \"0.1.8.10\",\n",
    "  \"forgebox\": \"0.4.18.5\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interact_manual\n",
    "from forgebox.imports import *\n",
    "from forgebox.category import Category\n",
    "from forgebox.html import DOM, list_group, list_group_kv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# for the purpose of easier developing\n",
    "# I'm using pytorch-lightning here\n",
    "# This is a questionable, tough and revokable dicision\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from typing import List, Dict, Callable, Any, Tuple\n",
    "from torchvision import transforms as tfm\n",
    "from PIL import Image\n",
    "from ipywidgets import (\n",
    "    VBox, HBox, HTML, Layout, Button, Output,\n",
    "    Text, Textarea, IntSlider, FloatSlider, SelectMultiple, Dropdown, Checkbox\n",
    ")\n",
    "from typing import List, Dict, Any, Callable\n",
    "from forgebox.thunder.callbacks import DataFrameMetricsCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's skip data download here, I mean it's download, we're not going to reinvent brilliant stuff around download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Everything starts with dataframe\n",
    "\n",
    "For fastai, everything starts from list, an **ItemList** to be specific. **ImageList** and **TextList** is [**ItemList**](https://fastai1.fast.ai/tutorial.itemlist.html) with some slight enhanced feature.```[üßÇ, üèì, üç∑, üêª]```\n",
    "\n",
    "For the clarity of education, or for simplecity as ultimate form of beauty, we use [**DataFrame**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) as starting point, ItemList in table format. In this way, every dataset has the same starting point, even the tabular data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase/ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Phase:\n",
    "    \"\"\"\n",
    "    A configuration management mechanism\n",
    "    \"\"\"\n",
    "    is_phase = True\n",
    "    def __init__(self, **kwargs):\n",
    "        self.config = dict()\n",
    "        self.config.update(kwargs)\n",
    "        \n",
    "    def __setitem__(self, k, v):\n",
    "        self.config[k] = v\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        return self.config[k]\n",
    "    \n",
    "    def __contains__(self, k):\n",
    "        return k in self.config\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.get_data(self.config)\n",
    "    \n",
    "    def get_data(self, raw):\n",
    "        \"\"\"\n",
    "        Reconstruct back to dict or list or value format\n",
    "        \"\"\"\n",
    "        if hasattr(raw,\"is_phase\"):\n",
    "            return raw.get_data(raw.config)\n",
    "        if type(raw) == list:\n",
    "            raw = list(self.get_data(i) for i in raw)\n",
    "            return raw\n",
    "        if type(raw) == dict:\n",
    "            for k, v in raw.items():\n",
    "                raw[k] = self.get_data(v)\n",
    "            return raw\n",
    "        return raw\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps(self(), indent=2)\n",
    "    \n",
    "    def __repr__(self,):\n",
    "        return f\"Phase:{self}\"\n",
    "    \n",
    "def save_phase():\n",
    "    global phase\n",
    "    global PROJECT\n",
    "    PROJECT = Path(PROJECT)\n",
    "    PROJECT.mkdir(exist_ok=True, parents=True)\n",
    "    with open(PROJECT/\"phase.json\", \"w\") as f:\n",
    "        f.write(str(phase))\n",
    "        \n",
    "def load_phase(new: bool=False):\n",
    "    global phase\n",
    "    global PROJECT\n",
    "    PROJECT = Path(PROJECT)\n",
    "    PROJECT.mkdir(exist_ok=True, parents=True)\n",
    "    if new:\n",
    "        return Phase()\n",
    "    if (PROJECT/\"phase.json\").exists():\n",
    "        with open(PROJECT/\"phase.json\", \"r\") as f:\n",
    "            phase = Phase(**json.loads(f.read()))\n",
    "            print(phase)\n",
    "    else:\n",
    "        phase = Phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widget Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flash:\n",
    "    @staticmethod\n",
    "    def create_msg_box(color, text, key:str = None):\n",
    "        text = str(text)\n",
    "        if key is not None:\n",
    "            key = f\"<strong>{key}</strong> \"\n",
    "        else:\n",
    "            key = \"\"\n",
    "        text_bar = HTML(f\"\"\"<div class='alert alert-{color}' role='alert'>\n",
    "        {key} {text}</div>\"\"\", layout=Layout(width='95%'))\n",
    "        close_btn = Button(description=\"x\", layout=Layout(width='3%'))\n",
    "        \n",
    "        total = HBox([text_bar, close_btn])\n",
    "        def close_bar():\n",
    "            total.close()\n",
    "        close_btn.click = close_bar\n",
    "        return total\n",
    "    \n",
    "    @classmethod\n",
    "    def get_info(cls, text, key:str = None):\n",
    "        return cls.create_msg_box('info', text, key)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_warning(cls, text, key:str = None):\n",
    "        return cls.create_msg_box('warning', text, key)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_danger(cls, text, key:str = None):\n",
    "        return cls.create_msg_box('danger', text, key)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_success(cls, text, key:str = None):\n",
    "        return cls.create_msg_box('success', text, key)\n",
    "    \n",
    "    @classmethod\n",
    "    def info(cls, text, key:str = None):\n",
    "        display(cls.get_info(text, key))\n",
    "    \n",
    "    @classmethod\n",
    "    def warning(cls, text, key:str = None):\n",
    "        display(cls.get_warning(text, key))\n",
    "    \n",
    "    @classmethod\n",
    "    def danger(cls, text, key:str = None):\n",
    "        display(cls.get_danger(text, key))\n",
    "    \n",
    "    @classmethod\n",
    "    def success(cls, text, key:str = None):\n",
    "        display(cls.get_success(text, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Editable List & Dict\n",
    "And editable list within jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_width = Layout(width=\"100%\")\n",
    "\n",
    "\n",
    "class EditableList(VBox):\n",
    "    \"\"\"\n",
    "    Interactive list\n",
    "    You can add item to the list\n",
    "    Each added item has a remove button to remove such item\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_list: List[Any] = [], pretty_json: bool = True):\n",
    "        super().__init__([], layout=total_width)\n",
    "        self.pretty_json = pretty_json\n",
    "        for data in data_list:\n",
    "            self+data\n",
    "\n",
    "    def create_line(self, data):\n",
    "        children = list(self.children)\n",
    "        children.append(self.new_line(data))\n",
    "        self.children = children\n",
    "\n",
    "    def data_to_dom(self, data):\n",
    "        if self.pretty_json:\n",
    "            pretty = list_group_kv(data) if hasattr(\n",
    "                data, \"keys\") else list_group(data)\n",
    "            return HTML(str(pretty), layout=total_width)\n",
    "        else:\n",
    "            return HTML(json.dumps(data))\n",
    "\n",
    "    def new_line(self, data) -> HBox:\n",
    "        del_btn = Button(description=\"Remove\", icon=\"trash\")\n",
    "        del_btn.button_style = 'danger'\n",
    "        hbox = HBox([del_btn, self.data_to_dom(data)],\n",
    "                    layout=total_width, box_style='info')\n",
    "        hbox.data = data\n",
    "\n",
    "        def remove_hbox():\n",
    "            children = list(self.children)\n",
    "            for i, c in enumerate(children):\n",
    "                if id(c) == id(hbox):\n",
    "                    children.remove(c)\n",
    "            self.children = children\n",
    "        del_btn.click = remove_hbox\n",
    "        return hbox\n",
    "\n",
    "    def __add__(self, data):\n",
    "        self.create_line(data)\n",
    "        return self\n",
    "\n",
    "    def get_data(self) -> List[Any]:\n",
    "        \"\"\"\n",
    "        Return the data of this list\n",
    "        \"\"\"\n",
    "        return list(x.data for x in self.children)\n",
    "\n",
    "\n",
    "class EditableDict(VBox):\n",
    "    \"\"\"\n",
    "    Interactive dictionary\n",
    "    You can add item to the dictionary\n",
    "    Each added item has a remove button to remove such item\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dict: Dict[str, Any] = dict(), pretty_json: bool = True):\n",
    "        super().__init__([], layout=total_width)\n",
    "        self.pretty_json = pretty_json\n",
    "        self+data_dict\n",
    "        \n",
    "    def on_update(self, func):\n",
    "        \"\"\"\n",
    "        A decorator to set a function\n",
    "        Every time the dict changed\n",
    "        Will execute this function\n",
    "        the default arg is the dictionary data\n",
    "        \"\"\"\n",
    "        self.update_func = func\n",
    "        return func\n",
    "    \n",
    "    def run_update(self):\n",
    "        if hasattr(self, \"update_func\"):\n",
    "            self.update_func(self.get_data())\n",
    "        \n",
    "    def create_line(self, key: str, data: Any):\n",
    "        children_map = dict((child.key, child) for child in self.children)\n",
    "        children_map[key] = self.new_line(key, data)\n",
    "        self.children = list(children_map.values())\n",
    "        self.run_update()\n",
    "        \n",
    "    def data_to_dom(self, data):\n",
    "        if self.pretty_json:\n",
    "            pretty = list_group_kv(data) if hasattr(\n",
    "                data, \"keys\") else list_group(data)\n",
    "            return HTML(str(pretty), layout=total_width)\n",
    "        else:\n",
    "            return HTML(json.dumps(data))\n",
    "\n",
    "    def new_line(self, key: str, data: Any) -> HBox:\n",
    "        del_btn = Button(description=\"Remove\", icon=\"trash\")\n",
    "        del_btn.button_style = 'danger'\n",
    "        key_info = HTML(f\"<h4 class='text-primary p-1'>{key}</h4>\")\n",
    "        hbox = HBox([VBox([key_info, del_btn]), self.data_to_dom(data)],\n",
    "                    layout=total_width, box_style='')\n",
    "        hbox.data = data\n",
    "        hbox.key = key\n",
    "\n",
    "        def remove_hbox():\n",
    "            children = list(self.children)\n",
    "            for c in children:\n",
    "                if id(c) == id(hbox):\n",
    "                    children.remove(c)\n",
    "            self.children = children\n",
    "            self.run_update()\n",
    "        del_btn.click = remove_hbox\n",
    "        return hbox\n",
    "    \n",
    "    def __setitem__(self, k, v):\n",
    "        self.create_line(k, v)\n",
    "    \n",
    "    def __add__(self, kv):\n",
    "        for k,v in kv.items():\n",
    "            self.create_line(k, v)\n",
    "        return self\n",
    "\n",
    "    def get_data(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Return the data of this dict\n",
    "        \"\"\"\n",
    "        return dict((x.key,x.data) for x in self.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StepByStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LivingStep:\n",
    "    \"\"\"\n",
    "    A step interactive for StepByStep\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, func: Callable,\n",
    "        top_block: HTML = None\n",
    "    ):\n",
    "        self.output = Output()\n",
    "        self.func = func\n",
    "        self.top_block = top_block\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        with self.output:\n",
    "            if self.top_block is not None:\n",
    "                display(self.top_block)\n",
    "            return self.func(**kwargs)\n",
    "\n",
    "    def new_top_block(self, top_block):\n",
    "        self.top_block = top_block\n",
    "\n",
    "\n",
    "class StepByStep:\n",
    "    \"\"\"\n",
    "    A tool to manage progress step by step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        funcs: Dict[str, Callable],\n",
    "        top_board: HTML = None,\n",
    "        kwargs: Dict[str, Any] = dict()\n",
    "    ):\n",
    "        self.step_keys: List[str] = list(funcs.keys())\n",
    "        self.steps: Dict[str, LivingStep] = dict(\n",
    "            (k, LivingStep(f)) for k, f in funcs.items())\n",
    "        self.furthest: int = 0\n",
    "        self.current: int = -1\n",
    "        self.kwargs: Dict[str, Any] = kwargs\n",
    "        self.execute_cache: Dict[str, bool] = dict()\n",
    "        self.top_board: HTML = top_board\n",
    "        self.page_output: Output = Output()\n",
    "        self.footer: Output = Output()\n",
    "        self.create_widget()\n",
    "\n",
    "    def rerun(self,**kwargs):\n",
    "        \"\"\"\n",
    "        Rerun the current step function\n",
    "        \"\"\"\n",
    "        # find the step\n",
    "        step: LivingStep = self.steps[self.step_keys[self.current]]\n",
    "        # clear old output\n",
    "        step.output.clear_output()\n",
    "        self.kwargs.update(kwargs)\n",
    "        step(progress=self, **self.kwargs)\n",
    "\n",
    "    def create_control_bar(self,):\n",
    "        self.bar_hbox = list()\n",
    "        self.next_btn: Button = Button(\n",
    "            description=\"Next\", icon='check', button_style='info')\n",
    "        self.rerun_btn = Button(description=\"Rerun Step\",\n",
    "                                icon='play', button_style='success')\n",
    "        self.title = HTML(f\"<h4 class='text-primary'>Step By Step</h4>\")\n",
    "        self.next_btn.click = self.next_step\n",
    "        self.rerun_btn.click = self.rerun\n",
    "        self.bar_hbox.append(self.title)\n",
    "        self.bar_hbox.append(self.next_btn)\n",
    "        self.bar_hbox.append(self.rerun_btn)\n",
    "        return HBox(self.bar_hbox)\n",
    "\n",
    "    def create_widget(self) -> None:\n",
    "        self.vbox_list = []\n",
    "        if self.top_board is not None:\n",
    "            self.vbox_list.append(self.top_board)\n",
    "        \n",
    "        # create buttons for progress axis\n",
    "        self.progress_btns = dict(\n",
    "            (k, Button(\n",
    "                description=f\"{i+1}:{k}\",\n",
    "                icon=\"cube\",\n",
    "                button_style=\"danger\"\n",
    "                if i <= self.furthest else \"\"))\n",
    "            for i, (k, v) in enumerate(self.steps.items())\n",
    "        )\n",
    "        # assign action to first button\n",
    "        first_btn: Button = list(self.progress_btns.values())[0]\n",
    "        first_btn.click: Callable = self.to_page_action(0)\n",
    "        self.progress_bar = HBox(list(self.progress_btns.values()))\n",
    "        \n",
    "        # assemble the entire widget\n",
    "        self.vbox_list.append(self.progress_bar)\n",
    "        self.vbox_list.append(self.create_control_bar())\n",
    "        self.vbox_list.append(self.page_output)\n",
    "        self.widget = VBox(self.vbox_list)\n",
    "\n",
    "    def to_page_action(\n",
    "        self, page_id: int\n",
    "    ) -> Callable:\n",
    "        \"\"\"\n",
    "        generate the button click function\n",
    "        \"\"\"\n",
    "        def to_page_func():\n",
    "            return self[page_id]\n",
    "        return to_page_func\n",
    "\n",
    "    def update_furthest(self):\n",
    "        \"\"\"\n",
    "        Update the \"furthest mark\"\n",
    "        Also enact the next progress button\n",
    "        \"\"\"\n",
    "        if self.furthest < self.current:\n",
    "            if self.current < len(self):\n",
    "                # update even button\n",
    "                btn = self.progress_btns[self.step_keys[self.current]]\n",
    "                btn.click = self.to_page_action(\n",
    "                    self.current)\n",
    "                btn.button_style = 'danger'\n",
    "            self.furthest = self.current\n",
    "            \n",
    "    def __repr__(self):\n",
    "        keys = \" => \".join(self.step_keys)\n",
    "        return f\"Progress Axis: [{keys}]\"\n",
    "\n",
    "    def __getitem__(self, page_id):\n",
    "        \"\"\"\n",
    "        Display a single page\n",
    "        \"\"\"\n",
    "        if (page_id < 0) or (page_id >= len(self)):\n",
    "            return\n",
    "        self.current: int = page_id\n",
    "        key: str = self.step_keys[page_id]\n",
    "        step: LivingStep = self.steps[key]\n",
    "        self.title.value: str = f\"<h4 class='text-danger'>Step {page_id+1}: {key}</h4>\"\n",
    "        self.page_output.clear_output()\n",
    "\n",
    "        with self.page_output:\n",
    "            display(step.output)\n",
    "        if key not in self.execute_cache:\n",
    "            rt = step(progress=self, **self.kwargs)\n",
    "            if hasattr(rt,\"keys\"):\n",
    "                self.kwargs(rt)\n",
    "            self.execute_cache[key] = True\n",
    "\n",
    "    def next_step(self, **kwargs):\n",
    "        self.current += 1\n",
    "        if self.current >= len(self):\n",
    "            self.current = 0\n",
    "        self.update_furthest()\n",
    "        return self[self.current]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.step_keys)\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Start the entire progress widget\n",
    "        \"\"\"\n",
    "        display(self.widget)\n",
    "        display(self.footer)\n",
    "        self.kwargs.update(kwargs)\n",
    "        self.next_step(**self.kwargs)\n",
    "\n",
    "    def show_in(self, step_name: str) -> Callable:\n",
    "        \"\"\"\n",
    "        A decorator that will make the function\n",
    "            to show under a specific step window\n",
    "        \"\"\"\n",
    "        step = self.steps[step_name]\n",
    "\n",
    "        def decorator(func: Callable) -> Callable:\n",
    "            def wrapper(*args, **kwargs):\n",
    "                with step.output:\n",
    "                    return func(*args, **kwargs)\n",
    "            return wrapper\n",
    "        return decorator\n",
    "\n",
    "    def show_footer(self, func: Callable):\n",
    "        \"\"\"\n",
    "        A decorator, where functions excuted\n",
    "            within this, will be showon under footer\n",
    "        \"\"\"\n",
    "        def wrapper(*args, **kwargs):\n",
    "            with self.footer:\n",
    "                return func(*args, **kwargs)\n",
    "        return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### typings for interactives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typing for interactive details\n",
    "```self()``` will create widgets automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveTyping:\n",
    "    \"\"\"\n",
    "    Typing for interactive details\n",
    "    self.__call__() will create widgets directly\n",
    "    \"\"\"\n",
    "    name = \"anything\"\n",
    "    is_typing = True\n",
    "\n",
    "    def solid(self, default) -> None:\n",
    "        \"\"\"\n",
    "        Reset default value\n",
    "        \"\"\"\n",
    "        if default is not None:\n",
    "            self.default = default\n",
    "\n",
    "\n",
    "class INT(InteractiveTyping):\n",
    "    def __init__(self, min_: int = 0, max_: int = 10, step: int = 1, default: int = None):\n",
    "        self.max_ = max_\n",
    "        self.min_ = min_\n",
    "        self.step = step\n",
    "        self.default = default if default is not None else 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"int[{self.min_}-{self.max_}, :{self.step}]={self.default}\"\n",
    "\n",
    "    def __call__(self, default: int = None):\n",
    "        self.solid(default)\n",
    "        return IntSlider(\n",
    "            value=self.default,\n",
    "            min=self.min_,\n",
    "            max=self.max_,\n",
    "            step=self.step,\n",
    "        )\n",
    "\n",
    "\n",
    "class BOOL(InteractiveTyping):\n",
    "    def __init__(self, name:str=\"\", default: bool = True,):\n",
    "        self.default = default\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"bool={self.default}\"\n",
    "\n",
    "    def __call__(self, default: bool = None) -> Checkbox:\n",
    "        self.solid(default)\n",
    "        return Checkbox(value=self.default, description=self.name)\n",
    "\n",
    "\n",
    "class FLOAT(InteractiveTyping):\n",
    "    def __init__(self, min_: int = -1., max_: int = 1., step: int = .01, default: int = None):\n",
    "        self.max_ = max_\n",
    "        self.min_ = min_\n",
    "        self.step = step\n",
    "        self.default = default if default is not None else 0.01\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"float[{self.min_}-{self.max_}, :{self.step}]={self.default}\"\n",
    "\n",
    "    def __call__(self, default: int = None):\n",
    "        self.solid(default)\n",
    "        return FloatSlider(\n",
    "            value=self.default,\n",
    "            min=self.min_,\n",
    "            max=self.max_,\n",
    "            step=self.step,\n",
    "        )\n",
    "\n",
    "\n",
    "class STR(InteractiveTyping):\n",
    "    \"\"\"\n",
    "    String object\n",
    "    will create text or textarea\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, default: str = None, use_area: bool = False):\n",
    "        \"\"\"\n",
    "        use_area: do we use Textarea, if False,we use Text\n",
    "        \"\"\"\n",
    "        self.default = \"\" if default is None else default\n",
    "        self.use_area = use_area\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"str='{self.default}'\"\n",
    "\n",
    "    def __call__(self, default: str = None):\n",
    "        self.solid(default)\n",
    "        if self.use_area:\n",
    "            return Textarea(value=self.default, layout=Layout(width=\"80%\"))\n",
    "        return Text(value=self.default)\n",
    "\n",
    "\n",
    "class LIST(InteractiveTyping):\n",
    "    \"\"\"\n",
    "    dropdown list type or multiselection type\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, options: List[Any] = [], default: Any = None, multi: bool = False):\n",
    "        \"\"\"\n",
    "        if multi: default should be iterable\n",
    "        else: default should be one of the option\n",
    "        \"\"\"\n",
    "        self.options = options\n",
    "        self.default = default\n",
    "        self.multi = multi\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.multi:\n",
    "            size = f\"[0-{self.default}]/{len(self.options)}\"\n",
    "        else:\n",
    "            size = f\"1/{len(self.options)}\"\n",
    "        return f\"list,{size}\"\n",
    "\n",
    "    def __call__(self, default: Any = None):\n",
    "        self.solid(default)\n",
    "        if self.multi:\n",
    "            inter = SelectMultiple(options=self.options)\n",
    "        else:\n",
    "            inter = Dropdown(options=self.options)\n",
    "\n",
    "        if self.default is not None:\n",
    "            # if multi: default should be iterable\n",
    "            # else: default should be one of the option\n",
    "            inter.value = self.default\n",
    "        return inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original ```interact_manual``` isn't powerful enough for this situation, so the following is a more flexible way to decorate an interactive function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveAnnotations:\n",
    "    \"\"\"\n",
    "    Build interactive based on the info of function's ```__annotations__```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, func: Callable,\n",
    "        icon: str = \"rocket\",\n",
    "        description: str = 'Run',\n",
    "        button_style='primary'\n",
    "    ):\n",
    "        self.func = func\n",
    "        self.icon = icon\n",
    "        self.button_style = button_style\n",
    "        self.description = description\n",
    "        self.build_vbox(func)\n",
    "\n",
    "    @classmethod\n",
    "    def on(\n",
    "        cls,\n",
    "        callback: Callable,\n",
    "        icon: str = 'rocket',\n",
    "        description: str = 'Run',\n",
    "        button_style: str = 'primary'\n",
    "    ) -> Callable:\n",
    "        \"\"\"\n",
    "        Use this class as a decorator\n",
    "        @InteractiveAnnotation.on(callback)\n",
    "        def target_func(a:STR(), b:INT()=1):\n",
    "            ...\n",
    "        \"\"\"\n",
    "        def decorator(func: Callable):\n",
    "            obj = cls(\n",
    "                func,\n",
    "                icon=icon,\n",
    "                description=description,\n",
    "                button_style=button_style\n",
    "            )\n",
    "            display(obj.vbox)\n",
    "            obj.register_callback(callback=callback)\n",
    "            return func\n",
    "        return decorator\n",
    "\n",
    "    def build_vbox(self, func: Callable):\n",
    "        row_list = []\n",
    "        self.fields = dict()\n",
    "        for k, v in func.__annotations__.items():\n",
    "            if hasattr(v, \"is_typing\") == False:\n",
    "                continue\n",
    "            widget = v()\n",
    "            widget.description = k\n",
    "            row_list.append(widget)\n",
    "            self.fields.update({k: widget})\n",
    "\n",
    "        # final button\n",
    "        self.final_btn = Button(\n",
    "            description=self.description,\n",
    "            icon=self.icon,\n",
    "        )\n",
    "        self.final_btn.button_style = self.button_style\n",
    "        row_list.append(self.final_btn)\n",
    "\n",
    "        # create interactive\n",
    "        self.vbox = VBox(row_list)\n",
    "        return self.vbox\n",
    "\n",
    "    def register_callback(\n",
    "        self,\n",
    "        callback: Callable\n",
    "    ) -> None:\n",
    "        def run_callback():\n",
    "            kwargs = self()\n",
    "            callback(kwargs)\n",
    "        self.final_btn.click = run_callback\n",
    "\n",
    "    def __call__(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        extract interactive data values\n",
    "        \"\"\"\n",
    "        rt = dict()\n",
    "        for k, widget in self.fields.items():\n",
    "            rt.update({k: widget.get_interact_value()})\n",
    "        return rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test callback & decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ee4c04e2504c43883cb7a86e8d0de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='a'), IntSlider(value=1, description='b', max=10), Button(button_sty‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_stuff(kwargs):\n",
    "    Flash.info(str(kwargs))\n",
    "\n",
    "@InteractiveAnnotations.on(print_stuff, \"flask\", \"test\", button_style=\"warning\")\n",
    "def some_func(e, a:STR(), b:INT()=2, d=3):\n",
    "    Flash.danger(str(kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercept interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kwargs(kwargs):\n",
    "    print(kwargs)\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def reconfig_manual_interact(\n",
    "    widget,\n",
    "    description: str = \"Create\",\n",
    "    button_style: str = \"primary\",\n",
    "    icon: str = \"plus\"\n",
    ") -> Button:\n",
    "    \"\"\"\n",
    "    reconfigure the button of interactive features\n",
    "    \"\"\"\n",
    "    btn = None\n",
    "    for w in widget.children:\n",
    "        if type(w) == Button:\n",
    "            btn = w\n",
    "            break\n",
    "    btn.description = description\n",
    "    btn.button_style = button_style\n",
    "    btn.icon = icon\n",
    "    return btn\n",
    "\n",
    "\n",
    "def interact_intercept(\n",
    "    func:Callable,\n",
    "    result_cb: Callable = print_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Initialize a class with interactive features\n",
    "    \"\"\"\n",
    "    annotations = func.__annotations__\n",
    "    defaults = func.__defaults__\n",
    "    kwargs = dict()\n",
    "    if defaults is not None:\n",
    "        for (k, typing), default in zip(annotations.items(), defaults):\n",
    "            kwargs.update({k: typing(default)})\n",
    "    obj = dict()\n",
    "\n",
    "    def fillin_init(**kwargs):\n",
    "        obj.update({\n",
    "            \"kwargs\": kwargs,\n",
    "        })\n",
    "    f = interact_manual(fillin_init, **kwargs)\n",
    "\n",
    "    btn = reconfig_manual_interact(f.widget)\n",
    "\n",
    "    if btn is not None:\n",
    "        original = btn.click\n",
    "\n",
    "        def new_click_event():\n",
    "            original()\n",
    "            return result_cb(obj['kwargs'])\n",
    "        btn.click = new_click_event\n",
    "\n",
    "    return obj, f\n",
    "\n",
    "def init_interact(cls, result_cb: Callable = print_kwargs):\n",
    "    return interact_intercept(cls.__init__, result_cb=result_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed01c9e58a56429b91ec27ab66339344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='RGB')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STR('RGB')()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich columns (feature transformation, label extraction)\n",
    "After this step, there will only be **MORE** column ‚ûï"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enrich:\n",
    "    \"\"\"\n",
    "    Enrich Base Class\n",
    "    Some default attributes\n",
    "    - is_enrich = True\n",
    "    - typing = None # output typing\n",
    "    - multi_cols = False # use multi-column as input\n",
    "    - prefer = None\n",
    "    - lazy = False  # shall we execute enrichment only through the iteration\n",
    "    - src = None # source column\n",
    "    \"\"\"\n",
    "    is_enrich = True\n",
    "    typing = None # output typing\n",
    "    multi_cols = False # use multi-column as input\n",
    "    prefer = None\n",
    "    lazy = False  # shall we execute enrichment only through the iteration\n",
    "    src = None # source column\n",
    "\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __call__(self, row):\n",
    "        return row\n",
    "    \n",
    "    def rowing(self, row):\n",
    "        if self.multi_cols:\n",
    "            return self(row)\n",
    "        else:\n",
    "            return self(row[self.src])\n",
    "\n",
    "\n",
    "class EnrichImage(Enrich):\n",
    "    \"\"\"\n",
    "    Create Image column from image path column\n",
    "    \"\"\"\n",
    "    prefer = \"QuantifyImage\"\n",
    "    typing = Image\n",
    "    lazy = True\n",
    "    \n",
    "\n",
    "    def __init__(\n",
    "        self, convert: STR(\"RGB\") = \"RGB\",\n",
    "        size: LIST(options=[28, 128, 224, 256, 512], default=224) = 224,\n",
    "    ):\n",
    "        self.convert = convert\n",
    "        self.size = size\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"[Image:{self.size}]\"\n",
    "\n",
    "    def __call__(self, x):\n",
    "        img = Image.open(x).convert(self.convert)\n",
    "        img = img.resize((self.size, self.size))\n",
    "        return img\n",
    "\n",
    "\n",
    "class ParentAsLabel(Enrich):\n",
    "    typing = str\n",
    "    prefer = \"QuantifyCategory\"\n",
    "    def __call__(self, path: Path,) -> str:\n",
    "        \"\"\"\n",
    "        Use parent folder name as label\n",
    "        \"\"\"\n",
    "        return Path(path).parent.name\n",
    "    \n",
    "ENRICHMENTS = dict(\n",
    "    EnrichImage=EnrichImage,\n",
    "    ParentAsLabel=ParentAsLabel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa00a07c8fbc466598bea1ad3a2b5b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='RGB', description='convert'), Dropdown(description='size', index=2, options=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj,f = init_interact(EnrichImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Enrich üé∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_enrich(**kwargs):\n",
    "    df = kwargs['df']\n",
    "    phase = kwargs['phase']\n",
    "\n",
    "    DOM(f\"{len(df)} rows of data, example table\", \"h3\")()\n",
    "    display(df.sample(5))\n",
    "    display(HTML(\"<hr>\"))\n",
    "\n",
    "    def setting_col():\n",
    "        enrich_data_list = phase['enrich'] if 'enrich' in phase else []\n",
    "        enrich_box = EditableList(enrich_data_list)\n",
    "        display(enrich_box)\n",
    "\n",
    "        \n",
    "        def set_enrich_(src=[\"[all_columns]\", ]+list(df.columns)):\n",
    "            DOM(f\"Setting up column enrich: {src}\", \"h4\")()\n",
    "            if src == \"[all_columns]\":\n",
    "                display(df.head(3))\n",
    "            else:\n",
    "                display(df[[src, ]].head(3))\n",
    "\n",
    "            def choose_enrich(dst=\"\", enrich=ENRICHMENTS):\n",
    "                DOM(f\"Source: {src}, Destination: {dst}, for {enrich.__name__}\", \"h4\")(\n",
    "                )\n",
    "                DOM(f\"{enrich.__doc__}\", \"quote\")()\n",
    "\n",
    "                def result_callback(kwargs):\n",
    "                    extra = {\"src\": src, \"dst\": dst,\n",
    "                                \"kwargs\": kwargs, \"enrich\": enrich.__name__}\n",
    "                    enrich_box+extra\n",
    "                    phase['enrich'] = enrich_box.get_data()\n",
    "                obj, decoed_func = init_interact(enrich, result_callback)\n",
    "            choose_enrich_widget = interact_manual(choose_enrich).widget\n",
    "            reconfig_manual_interact(\n",
    "                choose_enrich_widget,\n",
    "                description=\"Choose\", button_style='warning')\n",
    "        set_enrich_widget = interact_manual(set_enrich_).widget\n",
    "        reconfig_manual_interact(set_enrich_widget, button_style='warning')\n",
    "    setting_col()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute enrichment\n",
    "> apply the enrichment settings to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_enrich(\n",
    "    df: pd.DataFrame, phase:Phase\n",
    "):\n",
    "    if 'enrich' not in phase:\n",
    "        return df\n",
    "    for en_conf in tqdm(phase[\"enrich\"], leave=False):\n",
    "        enrich_name = en_conf['enrich']\n",
    "        enrich_cls = ENRICHMENTS[enrich_name]\n",
    "        kwargs = en_conf['kwargs']\n",
    "        src = en_conf['src']\n",
    "        dst = en_conf['dst']\n",
    "        # The class with lazy loading, will only \n",
    "        # call the class only if necessary\n",
    "        if enrich_cls.lazy:\n",
    "            obj = enrich_cls(**kwargs)\n",
    "            obj.src = src\n",
    "            df[dst] = obj\n",
    "        # The class without lazy loading\n",
    "        # create the column now\n",
    "        else:\n",
    "            obj = enrich_cls(**kwargs)\n",
    "            if src==\"[all_columns]\":\n",
    "                df[dst] = df.apply(obj, axis=1)\n",
    "            else:\n",
    "                df[dst] = df[src].apply(obj)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify: Choose columns as X and Y, put them into number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIZE_DIMENSION:\n",
    "    pass\n",
    "\n",
    "class BATCH_SIZE(SIZE_DIMENSION):\n",
    "    def __repr__(self): return f\"BATCH_SIZE\"\n",
    "\n",
    "class SEQUENCE_SIZE(SIZE_DIMENSION):\n",
    "    pass\n",
    "\n",
    "class IMAGE_SIZE(SIZE_DIMENSION):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = Category([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Quantify:\n",
    "    is_quantify = True\n",
    "    \"\"\"\n",
    "    # From all things to number\n",
    "    The AI model does not understand anything, say, picture, text\n",
    "    Unless you transform it to integer and float tensors\n",
    "\n",
    "    Quantify and its subclass controls the\n",
    "        numericalization / collation of the data pipeline\n",
    "    The base class of quantify does: NOTHING\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, list_of_items):\n",
    "        return list(list_of_items)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        \"\"\"\n",
    "        A function to let the data processing\n",
    "        adapt to the data column\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __hash__(self,):\n",
    "        if hasattr(self, \"name\"):\n",
    "            return self.name\n",
    "        else:\n",
    "            return self.__class__.__name__\n",
    "\n",
    "\n",
    "class QuantifyImage(Quantify):\n",
    "    \"\"\"\n",
    "    Transform PIL.Image to tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mean_: LIST([\"imagenet\", \"0.5 x 3\"]) = \"imagenet\",\n",
    "        std_: LIST([\"imagenet\", \"0.5 x 3\"]) = \"imagenet\",\n",
    "    ):\n",
    "        if type(mean_) == str:\n",
    "            if mean_ == \"imagenet\":\n",
    "                mean_ = [0.485, 0.456, 0.406]\n",
    "            elif mean_ == \"0.5 x 3\":\n",
    "                mean_ = [.5, .5, .5]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Mean configuration: {mean_} not valid\")\n",
    "\n",
    "        if type(std_) == str:\n",
    "            if std_ == \"imagenet\":\n",
    "                std_ = [0.229, 0.224, 0.225]\n",
    "            elif std_ == \"0.5 x 3\":\n",
    "                std_ = [.5, .5, .5]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Standard Variation configuration: {std_} not valid\")\n",
    "\n",
    "        self.transform = tfm.Compose([\n",
    "            tfm.ToTensor(),\n",
    "            tfm.Normalize(mean=mean_, std=std_),\n",
    "        ])\n",
    "\n",
    "        self.shape = (BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Quantify Image to tensors:{self.transform}\"\n",
    "\n",
    "    def __call__(self, list_of_image):\n",
    "        return torch.stack(list(\n",
    "            self.transform(img) for img in list_of_image))\n",
    "\n",
    "\n",
    "class QuantifyText(Quantify):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained: STR(default=\"bert-base-cased\") = \"bert-base-cased\",\n",
    "        max_length: INT(default=512, min_=12, max_=1024, step=4) = 512,\n",
    "        padding: LIST(options=[\n",
    "            \"do_not_pad\",\n",
    "            \"max_length\",\n",
    "            \"longest\"], default=\"max_length\") = \"max_length\",\n",
    "        return_token_type_ids: BOOL(name=\"Token Type IDs\", default=True) = True,\n",
    "        return_attention_mask: BOOL(name=\"Attention Mask\", default=True) = True,\n",
    "        return_offsets_mapping: BOOL(name=\"Offset Mapping\", default=False) = False,\n",
    "    ):\n",
    "        self.pretrained = pretrained\n",
    "        self.max_length = max_length\n",
    "        self.padding = padding\n",
    "        self.return_token_type_ids = return_token_type_ids\n",
    "        self.return_attention_mask = return_attention_mask\n",
    "        self.return_offsets_mapping = return_offsets_mapping\n",
    "        self.truncation = True\n",
    "        self.return_tensors = 'pt'\n",
    "        self.shape = (BATCH_SIZE, SEQUENCE_SIZE)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        \"\"\"\n",
    "        Initialize tokenizer\n",
    "        \"\"\"\n",
    "        from transformers import AutoTokenizer\n",
    "        Flash.info(\"Loading transformer tokenizer, takes time\", key=\"Alert!\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.pretrained, use_fast=True)\n",
    "\n",
    "    def __call__(self, list_of_text: List[str]):\n",
    "        list_of_text = list(list_of_text)\n",
    "        return self.tokenizer(\n",
    "            list_of_text,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            truncation=self.truncation,\n",
    "            return_token_type_ids=self.return_token_type_ids,\n",
    "            return_attention_mask=self.return_attention_mask,\n",
    "            return_tensors=self.return_tensors,\n",
    "            return_offsets_mapping=self.return_offsets_mapping,\n",
    "        )\n",
    "\n",
    "\n",
    "class QuantifyCategory(Quantify):\n",
    "    \"\"\"\n",
    "    Transform single categorical data to index numbers in pytorch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_frequency: INT(min_=1, max_=20, default=1) = 1,\n",
    "    ):\n",
    "        self.min_frequency = min_frequency\n",
    "\n",
    "    def adapt(self, column):\n",
    "        # category statistics\n",
    "        value_counts = pd.DataFrame(column.value_counts())\n",
    "\n",
    "        # if minimun freq is 1\n",
    "        # very category occured should be accounted for\n",
    "        # hence no missing token padding is required\n",
    "        if self.min_frequency < 2:\n",
    "            self.category = Category(\n",
    "                arr=np.array(value_counts.index),\n",
    "                pad_mst=False)\n",
    "\n",
    "        # we need missing token\n",
    "        # for category's frequency < self.min_frequency\n",
    "        else:\n",
    "            categories = np.array(\n",
    "                list(value_counts.index[\n",
    "                    value_counts.values.reshape(-1) > self.min_frequency]))\n",
    "            self.category = Category(arr=categories, pad_mst=True)\n",
    "\n",
    "        self.shape = (BATCH_SIZE, len(self.category))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Quantify Category:{self.category}\"\n",
    "\n",
    "    def __call__(self, list_of_strings):\n",
    "        return torch.LongTensor(self.category.c2i[np.array(list_of_strings)])\n",
    "\n",
    "\n",
    "class QuantifyMultiCategory(Quantify):\n",
    "    \"\"\"\n",
    "    Transform multi-categorical data to index numbers in pytorch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_frequency: INT(min_=1, max_=20, default=1) = 1,\n",
    "        separator: LIST(options=[\"[None]\", \",\", \";\", \"[Space]\", \"[By Char]\"], default=\",\") = \",\",\n",
    "    ):\n",
    "        self.min_frequency = min_frequency\n",
    "        friendly_mapping = {\n",
    "            \"[None]\": None,\n",
    "            \"[Space]\": \" \",\n",
    "            \"[By Char]\": \"\",\n",
    "        }\n",
    "        if separator in friendly_mapping:\n",
    "            separator = friendly_mapping.get(separator)\n",
    "        self.separator = separator\n",
    "\n",
    "    @staticmethod\n",
    "    def stripping(x):\n",
    "        return x.strip()\n",
    "\n",
    "    def break_cell(self, value):\n",
    "        if value is None:\n",
    "            return []\n",
    "        break_list = list(i for i in map(\n",
    "            self.stripping, str(value).split(self.separator)) if len(i) > 0)\n",
    "        return break_list\n",
    "\n",
    "    def adapt(self, column):\n",
    "        if self.separator is None:\n",
    "            sample_col = column\n",
    "        else:\n",
    "            sample_col = column.apply(self.break_cell)\n",
    "        value_counts = pd.DataFrame(sample_col.explode().value_counts())\n",
    "\n",
    "        # if minimun freq is 1\n",
    "        # very category occured should be accounted for\n",
    "        # hence no missing token padding is required\n",
    "        if self.min_frequency < 2:\n",
    "            self.category = Category(\n",
    "                arr=np.array(value_counts.index),\n",
    "                pad_mst=False)\n",
    "\n",
    "        # we need missing token\n",
    "        # for category's frequency < self.min_frequency\n",
    "        else:\n",
    "            categories = np.array(\n",
    "                list(value_counts.index[\n",
    "                    value_counts.values.reshape(-1) > self.min_frequency]))\n",
    "            self.category = Category(arr=categories, pad_mst=True)\n",
    "\n",
    "    def __call__(\n",
    "        self, list_of_strings: List[str]\n",
    "    ) -> torch.LongTensor:\n",
    "        \"\"\"\n",
    "        Return a batch of n-hot array tensor\n",
    "        \"\"\"\n",
    "        if self.separator is None:\n",
    "            col: List[str] = list_of_strings\n",
    "        else:\n",
    "            col: List[List[str]] = list(map(self.break_cell, list_of_strings))\n",
    "        arrays: List[np.array] = []\n",
    "        for item in col:\n",
    "            array: np.array = np.zeros(len(self.category))\n",
    "            if len(item) > 0:\n",
    "                one_idx: np.array = self.category.c2i[item]\n",
    "                array[one_idx] = 1\n",
    "            arrays.append(array)\n",
    "        return torch.LongTensor(np.stack(arrays))\n",
    "\n",
    "\n",
    "class QuantifyNum(Quantify):\n",
    "    \"\"\"\n",
    "    Quantify contineous data, like float numbers\n",
    "    The only process is normalization on the entire population\n",
    "    \"\"\"\n",
    "    shape = (BATCH_SIZE, 1)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        self.mean_ = column.mean()\n",
    "        self.std_ = column.std()\n",
    "\n",
    "    def __call__(self, list_of_num):\n",
    "        return (torch.FloatTensor(list_of_num)[:, None]-self.mean_)/self.std_\n",
    "\n",
    "    def backward(self, x):\n",
    "        return x*self.std_+self.mean_\n",
    "\n",
    "\n",
    "QUANTIFY = dict(\n",
    "    Quantify=Quantify,\n",
    "    QuantifyNum=QuantifyNum,\n",
    "    QuantifyImage=QuantifyImage,\n",
    "    QuantifyCategory=QuantifyCategory,\n",
    "    QuantifyMultiCategory=QuantifyMultiCategory,\n",
    "    QuantifyText=QuantifyText,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A pytorch dataset working under our core engine\n",
    "    The dataset class should on be defined here once\n",
    "    \"\"\"\n",
    "    def __init__(self, df, columns: List[Any] = None):\n",
    "        self.df = df\n",
    "        self.columns = list(df.columns) if columns is None else columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        row = dict(self.df.loc[idx])\n",
    "        rt = dict()\n",
    "        for col in self.columns:\n",
    "            v = row[col]\n",
    "            if hasattr(v, \"is_enrich\"):\n",
    "                rt[col] = v.rowing(row)\n",
    "            else:\n",
    "                rt[col] = v\n",
    "        return rt\n",
    "    \n",
    "    def split(\n",
    "        self,\n",
    "        valid_ratio:FLOAT(min_=0.01, max_=0.5, default=.1, step=0.01)=.1\n",
    "    ) -> Tuple[Any]:\n",
    "        \"\"\"\n",
    "        Split dataset to train, validation\n",
    "        \"\"\"\n",
    "        cls = self.__class__\n",
    "        slicing = (np.random.rand(len(self)) < valid_ratio)\n",
    "        return (\n",
    "            cls(self.df[~slicing].reset_index(drop=True), self.columns),\n",
    "            cls(self.df[slicing].reset_index(drop=True), self.columns)\n",
    "        )\n",
    "\n",
    "    def dataloader(\n",
    "        self,\n",
    "        batch_size: LIST(options=[1, 2, 4, 8, 16, 32, 64, 128, 256, 512], default=32) = 32,\n",
    "        shuffle: LIST(options=[True, False], default=False) = False,\n",
    "        num_workers: LIST(options=[0, 2, 4, 8, 16], default=0) =0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create dataloader from dataset\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose XY üé∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_xy(**kwargs):\n",
    "    df = kwargs.get(\"df\")\n",
    "    phase = kwargs.get(\"phase\")\n",
    "    progress = kwargs.get('progress')\n",
    "\n",
    "    DOM(f\"{len(df)} rows of data, example table\", \"h3\")()\n",
    "    display(df.sample(5))\n",
    "    display(HTML(\"<hr>\"))\n",
    "    DOM(\"Please Choose Column\", \"h3\")()\n",
    "    DOM(\"The AI model will try to guess the Y with the input X\", \"div\", {\"style\":\"color:#666699\"})()\n",
    "    \n",
    "    task = 'quantify'\n",
    "    # enrich by columns\n",
    "    if \"enrich\" in phase:\n",
    "        by_destination = dict((en['dst'], en) for en in phase['enrich'])\n",
    "    else:\n",
    "        by_destination = dict()\n",
    "    \n",
    "    data_list = phase[task] if task in phase else []\n",
    "    mol_box = EditableList(data_list)\n",
    "    display(mol_box)\n",
    "\n",
    "    @interact_manual\n",
    "    def set_quantify_(src=list(df.columns), use_for = [\"As X\", \"As Y\"]):\n",
    "        DOM(f\"Quantify Column: {src} {use_for}\", \"h4\")()\n",
    "        display(df[[src, ]].head(3))\n",
    "        \n",
    "        quantify_dropdown = Dropdown(options=list(QUANTIFY.keys()))\n",
    "        \n",
    "        # check the hint from last step\n",
    "        prefer = None\n",
    "        if src in by_destination:\n",
    "            col_config = by_destination[src]\n",
    "            cls = ENRICHMENTS[col_config['enrich']]\n",
    "\n",
    "            # In case the enrich layer has the preference\n",
    "            if hasattr(cls, \"prefer\"):\n",
    "                prefer = cls.prefer\n",
    "                \n",
    "                # set default value to drop down value,\n",
    "                # if the the previous hint suggest so\n",
    "                quantify_dropdown.value = prefer\n",
    "                DOM(f\"Prefered quantifying:\\t{cls.prefer}\", \"h4\")()\n",
    "            if hasattr(cls, \"typing\"):\n",
    "                DOM(f\"Output data type:\\t{cls.typing}\", \"h4\")()\n",
    "        \n",
    "        @interact_manual\n",
    "        def choose_quantify(quantify = quantify_dropdown):\n",
    "            cls = QUANTIFY[quantify]\n",
    "            def result_callback(kwargs):\n",
    "                extra = {\"src\": src, \"x\":(use_for==\"As X\"),\n",
    "                        \"kwargs\": kwargs, \"quantify\": cls.__name__}\n",
    "                mol_box+extra\n",
    "                phase['quantify'] = mol_box.get_data()\n",
    "                \n",
    "            obj, decoded = init_interact(cls, result_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_quantify(\n",
    "    df: pd.DataFrame, phase:Phase\n",
    "):\n",
    "    # existance check\n",
    "    if 'quantify' not in phase:\n",
    "        raise KeyError(f\"No quantify stepset\")\n",
    "    \n",
    "    qdict = dict()\n",
    "    for i, qconf in tqdm(enumerate(phase['quantify']), leave = False):\n",
    "        qname = qconf['quantify']\n",
    "        kwargs = qconf['kwargs']\n",
    "        src = qconf['src']\n",
    "        x = qconf['x']\n",
    "        \n",
    "        cls = QUANTIFY[qname]\n",
    "        qobj = cls(**kwargs)\n",
    "        qobj.src = src\n",
    "        qobj.is_x = x\n",
    "        qobj.adapt(df[src])\n",
    "        qdict.update({src:qobj})\n",
    "    return qdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataloader\n",
    "This part handles:\n",
    "* Spliting\n",
    "* To dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiCollate:\n",
    "    \"\"\"\n",
    "    Universal all power full collate function\n",
    "    1 for all collation\n",
    "    \"\"\"\n",
    "    def __init__(self, quantify_dict):\n",
    "        self.quantify_dict = quantify_dict\n",
    "        \n",
    "    def make_df(self, batch):\n",
    "        return pd.DataFrame(list(batch))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.quantify_dict)\n",
    "        \n",
    "    def __call__(self, batch) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        This call will execute the __call__(a_list_of_items)\n",
    "        from Quantify objects column by column\n",
    "        \"\"\"\n",
    "        batch_df = self.make_df(batch)\n",
    "        rt = dict()\n",
    "        for src,qobj in self.quantify_dict.items():\n",
    "            rt.update({\n",
    "                src:qobj(list(batch_df[src]))\n",
    "            })\n",
    "        return rt\n",
    "\n",
    "class TaiChiDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset: TaiChiDataset, quantify_dict: Dict[str, Quantify]):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.quantify_dict = quantify_dict\n",
    "        \n",
    "        self.collate = TaiChiCollate(quantify_dict)\n",
    "        \n",
    "    def configure(\n",
    "        self,\n",
    "        valid_ratio:FLOAT(min_=0.01, max_=0.5, default=.1, step=0.01)=.1,\n",
    "        batch_size: LIST(options=[1, 2, 4, 8, 16, 32, 64, 128, 256, 512], default=32) = 32,\n",
    "        shuffle: LIST(options=[True, False], default=False) = True,\n",
    "        num_workers: LIST(options=[0, 2, 4, 8, 16], default=0) =0,\n",
    "    ):  \n",
    "        self.train_ds, self.val_ds = self.dataset.split(valid_ratio)\n",
    "        self.batch_size=batch_size\n",
    "        self.shuffle=shuffle\n",
    "        self.num_workers=num_workers\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        self.train_dl = self.train_ds.dataloader(\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers)\n",
    "        self.train_dl.collate_fn = self.collate\n",
    "        return self.train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        self.val_dl = self.val_ds.dataloader(\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers)\n",
    "        self.val_dl.collate_fn = self.collate\n",
    "        return self.val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Choose your model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import (\n",
    "    resnet18, resnet34, resnet50, resnet101, resnet152,\n",
    "    resnext101_32x8d, resnext50_32x4d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESNET_OPTIONS = {\"resnet18\": resnet18,\n",
    "                  \"resnet34\": resnet34,\n",
    "                  \"resnet50\": resnet50,\n",
    "                  \"resnet101\": resnet101,\n",
    "                  \"resnet152\": resnet152,\n",
    "                  \"resnext101_32x8d\": resnext101_32x8d,\n",
    "                  \"resnext50_32x4d\": resnext50_32x4d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidJoint1d(nn.Module):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "    \n",
    "    def forward(self, data):\n",
    "        tensors = list(data[key] for key in self.keys)\n",
    "        return torch.cat(tensors,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntryModel(nn.Module):\n",
    "    is_entry = True\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, ):\n",
    "        raise ImportError(\n",
    "            f\"Please define class function 'from_quantify' for {cls.__name__}\"\n",
    "        )\n",
    "    \n",
    "class Empty(EntryModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.out_features=1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls,\n",
    "        quantify):\n",
    "        return cls()\n",
    "\n",
    "class ImageConvEncoder(EntryModel):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.name = \"cnn\"\n",
    "        self.output_shape = (BATCH_SIZE, model.fc.in_features)\n",
    "        self.out_features = model.fc.in_features\n",
    "        model.fc = Empty()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"\"\"ComputerVisionEncoder: {self.name}\n",
    "        Outputs shape:{self.output_shape}\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        name: LIST(options=list(\n",
    "            RESNET_OPTIONS.keys()), default=\"resnet18\"),\n",
    "    ):\n",
    "        model = RESNET_OPTIONS[name](pretrained=True, progress=True,)\n",
    "        obj = cls(model)\n",
    "        obj.name = name\n",
    "        return obj\n",
    "\n",
    "\n",
    "class CategoryEncoder(EntryModel):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Embedding(\n",
    "            num_embeddings,\n",
    "            embedding_dim)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        return self.model(idx)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        embedding_dim: LIST(\n",
    "            options=[4, 8, 16, 32, 64, 128, 256, 512], default=128) = 128):\n",
    "        num_embeddings = len(quantify.category)\n",
    "        obj = CategoryEncoder(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "        obj.out_features = embedding_dim\n",
    "        return obj\n",
    "    \n",
    "class MultiCategoryEncoder(EntryModel):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Embedding(\n",
    "            num_embeddings,\n",
    "            embedding_dim)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        return idx.float()@self.model.weight\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        embedding_dim: LIST(\n",
    "            options=[4, 8, 16, 32, 64, 128, 256, 512], default=128) = 128):\n",
    "        num_embeddings = len(quantify.category)\n",
    "        obj = MultiCategoryEncoder(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "        obj.out_features = embedding_dim\n",
    "        return obj\n",
    "\n",
    "\n",
    "class TransformerEncoder(EntryModel):\n",
    "    \"\"\"\n",
    "    A model part to encode sequnce data in to vectors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, encoder_mode: BOOL(default=True) = True,):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.encoder_mode = encoder_mode\n",
    "\n",
    "    def forward(self, kwargs):\n",
    "        outputs = self.model(**kwargs)\n",
    "        if self.encoder_mode:\n",
    "            # output vector\n",
    "            if \"pooler_output\" in outputs:\n",
    "                return outputs.pooler_output\n",
    "            else:\n",
    "                return (\n",
    "                    outputs.last_hidden_state*kwargs['attention_mask'][:,:,None]\n",
    "                ).mean(1)\n",
    "        return outputs\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        name: STR(default=\"bert-base-uncased\") = 'bert-base-uncased',\n",
    "        encoder_mode: BOOL(default=True) = True,\n",
    "    ):\n",
    "        from transformers import AutoModel\n",
    "        model = AutoModel.from_pretrained(name)\n",
    "        obj = cls(model)\n",
    "        obj.name = name\n",
    "        obj.encoder_mode = encoder_mode\n",
    "        if encoder_mode:\n",
    "            obj.out_features= model.config.hidden_size\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry = TransformerEncoder.from_quantify(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     vector = entry(data['review_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry = ImageConvEncoder.from_quantify(0,name=\"resnet18\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     vectors = entry(data['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exit modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_, y):\n",
    "    return (y_.argmax(-1) == y).float().mean()\n",
    "\n",
    "def bi_accuracy(y_, y):\n",
    "    return ((y_>.5).float() == y).float().mean()\n",
    "\n",
    "class BCEWithLogitsLossCasted(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce_ = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, y_, y):\n",
    "        return self.bce_(y_,y.float())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExitModel(nn.Module):\n",
    "    metric_funcs = dict()\n",
    "\n",
    "    def loss_step(self, x, y):\n",
    "        y_ = self(x)\n",
    "        loss = self.crit(y_, y)\n",
    "        metrics = dict()\n",
    "        if hasattr(self, \"activation\"):\n",
    "            y_ = self.activation(y_)\n",
    "        for k, func in self.metric_funcs.items():\n",
    "            metrics.update({k: func(y_, y)})\n",
    "        return dict(loss=loss, y_=y_, **metrics)\n",
    "\n",
    "\n",
    "class CategoryTop(ExitModel):\n",
    "    prefer = \"CrossEntropyLoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.activation = nn.Softmax(dim=-1)\n",
    "        self.crit = nn.CrossEntropyLoss()\n",
    "        self.metric_funcs.update({\"acc\": accuracy})\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = len(quantify.category)\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )\n",
    "\n",
    "\n",
    "class MultiCategoryTop(ExitModel):\n",
    "    prefer = \"BCEWithLogitsLossCasted\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.crit = BCEWithLogitsLossCasted()\n",
    "        self.metric_funcs.update({\"acc\": bi_accuracy})\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = len(quantify.category)\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )\n",
    "\n",
    "\n",
    "class RegressionTop(ExitModel):\n",
    "    prefer = \"MSELoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.crit = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = 1\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EntireModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping quantify to the following entry or exit model\n",
    "QUANTIFY_2_ENTRY_MAP = dict({\n",
    "    QuantifyImage:[\n",
    "        ImageConvEncoder,\n",
    "    ],\n",
    "    QuantifyCategory:[\n",
    "        CategoryEncoder,\n",
    "    ],\n",
    "    QuantifyMultiCategory:[\n",
    "        MultiCategoryEncoder,\n",
    "    ],\n",
    "    QuantifyText:[\n",
    "        TransformerEncoder,\n",
    "    ],\n",
    "    QuantifyNum:[\n",
    "        Empty,\n",
    "    ],\n",
    "})\n",
    "QUANTIFY_2_EXIT_MAP = dict({\n",
    "    QuantifyCategory:[\n",
    "        CategoryTop,\n",
    "    ],\n",
    "    QuantifyMultiCategory:[\n",
    "        MultiCategoryTop,\n",
    "    ],\n",
    "    QuantifyNum:[\n",
    "        RegressionTop,\n",
    "    ],\n",
    "})\n",
    "\n",
    "# all entry and exit model\n",
    "ENTRY_ALL = dict(\n",
    "    ImageConvEncoder=ImageConvEncoder,\n",
    "    CategoryEncoder=CategoryEncoder,\n",
    "    MultiCategoryEncoder=MultiCategoryEncoder,\n",
    "    TransformerEncoder=TransformerEncoder,\n",
    "    Empty=Empty,\n",
    ")\n",
    "EXIT_ALL = dict(\n",
    "    CategoryTop=CategoryTop,\n",
    "    MultiCategoryTop=MultiCategoryTop,\n",
    "    RegressionTop=RegressionTop,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_models(\n",
    "    quantify,\n",
    "    cls_options,\n",
    "    model_conf: EditableDict,\n",
    "):\n",
    "    def config_model(ModelClass=cls_options):\n",
    "        def starting_cls(kwargs):\n",
    "            model_conf[quantify.src] = dict(\n",
    "                model_name=ModelClass.__name__,\n",
    "                src=quantify.src,\n",
    "                kwargs=kwargs,\n",
    "            )\n",
    "\n",
    "        ia = InteractiveAnnotations(\n",
    "            ModelClass.from_quantify,\n",
    "            description=\"Okay\",\n",
    "            icon='rocket',\n",
    "            button_style='success')\n",
    "\n",
    "        ia.register_callback(starting_cls)\n",
    "        display(ia.vbox)\n",
    "    inter = interact_manual(config_model)\n",
    "    reconfig_manual_interact(\n",
    "        inter.widget,\n",
    "        description=\"Yes!\", icon=\"cube\", button_style='info')\n",
    "    return inter\n",
    "\n",
    "\n",
    "def set_model(quantify_dict: Dict[str, Quantify], phase: Phase):\n",
    "    display(HTML(\"\"\"<h3>Set up model structure</h3>\n",
    "    <quote>You'll have to setup a model part for each of the column</quote>\"\"\"))\n",
    "\n",
    "    x_models = EditableDict()\n",
    "    y_models = EditableDict()\n",
    "\n",
    "    if \"x_models\" in phase:\n",
    "        x_models + phase['x_models']\n",
    "    if \"y_models\" in phase:\n",
    "        y_models + phase['y_models']\n",
    "    display(HTML(\"<h3>Current model config:</h3>\"))\n",
    "    display(HTML(f\"\"\"\n",
    "    <h3 class='text-primary'>ü§ñ <strong>Entry</strong> parts of the model</h3>\n",
    "    <h4>To understand the X columns</h4>\n",
    "    \"\"\"))\n",
    "    display(x_models)\n",
    "    display(HTML(f\"\"\"\n",
    "    <h3 class='text-danger'>ü¶æ <strong>Exit</strong> parts of the model</h3>\n",
    "    <h4>To understand & predict the Y column</h4>\n",
    "    \"\"\"))\n",
    "    display(y_models)\n",
    "\n",
    "    @x_models.on_update\n",
    "    def update_x_models(x_models_data):\n",
    "        phase['x_models'] = x_models_data\n",
    "\n",
    "    @y_models.on_update\n",
    "    def update_y_models(y_models_data):\n",
    "        phase['y_models'] = y_models_data\n",
    "\n",
    "    display(HTML(\"<h4>Change model config:</h4>\"))\n",
    "    for src, quantify in quantify_dict.items():\n",
    "        if quantify.is_x:\n",
    "            entry_cls_options = dict(\n",
    "                (q.__name__, q)\n",
    "                for q in QUANTIFY_2_ENTRY_MAP.get(quantify.__class__))\n",
    "\n",
    "            if entry_cls_options is None:\n",
    "                Flash.danger(\n",
    "                    f\"We do not support {quantify.__class__} as X data\",\n",
    "                    key=\"Error!\")\n",
    "                continue\n",
    "            display(HTML(f\"\"\"\n",
    "            <h3 class='text-primary'>Choose Model For X Columns:\n",
    "            <strong>{src}</strong></h3>\"\"\"))\n",
    "            choose_models(quantify, entry_cls_options, x_models)\n",
    "    for src, quantify in quantify_dict.items():\n",
    "        if quantify.is_x == False:\n",
    "            exit_cls_options = dict(\n",
    "                (q.__name__, q)\n",
    "                for q in QUANTIFY_2_EXIT_MAP.get(quantify.__class__))\n",
    "            if entry_cls_options is None:\n",
    "                Flash.danger(\n",
    "                    f\"We do not support {quantify.__class__} as Y data\",\n",
    "                    key=\"Error!\"\n",
    "                )\n",
    "            display(HTML(f\"\"\"\n",
    "            <h3 class='text-danger'>Choose Model For Y Column:\n",
    "            <strong>{src}</strong></h3>\"\"\"))\n",
    "            choose_models(quantify, exit_cls_options, y_models)\n",
    "\n",
    "\n",
    "def set_datamodule(progress, df, qdict, phase):\n",
    "    ds = TaiChiDataset(df)\n",
    "    datamodule = TaiChiDataModule(ds, qdict)\n",
    "\n",
    "    batch_level = EditableDict()\n",
    "    if \"batch_level\" in phase:\n",
    "        batch_level['batch_level'] = phase['batch_level']\n",
    "    display(HTML(\"<h3>How we make data rows into batch</h3>\"))\n",
    "    display(batch_level)\n",
    "    model_output = Output()\n",
    "\n",
    "    def configure_setting(kwargs):\n",
    "        batch_level['batch_level'] = kwargs\n",
    "        phase['batch_level'] = kwargs\n",
    "        set_model_btn_event()\n",
    "\n",
    "    def set_model_btn_event():\n",
    "        if 'batch_level' not in phase:\n",
    "            Flash.warning(\"batch level config not set\",\n",
    "                          key=\"Warning\")\n",
    "            return\n",
    "        datamodule.configure(**phase['batch_level'])\n",
    "        progress.kwargs['datamodule'] = datamodule\n",
    "\n",
    "        model_output.clear_output()\n",
    "        with model_output:\n",
    "            set_model(qdict, phase)\n",
    "\n",
    "    interact_intercept(datamodule.configure, configure_setting)\n",
    "\n",
    "    set_model_btn = Button(description=\"Set Batch\",\n",
    "                           icon='cog', button_style='info')\n",
    "    set_model_btn.click = set_model_btn_event\n",
    "    display(set_model_btn)\n",
    "    display(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntryDict(nn.Module):\n",
    "    \"\"\"\n",
    "    Create entry parts for different columns\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        phase: Phase,\n",
    "        qdict: Dict[str, EntryModel]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        model_dict = nn.ModuleDict()\n",
    "        for src, model_cfg in phase['x_models'].items():\n",
    "            quantify = qdict[src]\n",
    "            \n",
    "            # find column class\n",
    "            model_cls = ENTRY_ALL[model_cfg['model_name']]\n",
    "            # the kwargs to start the column model object\n",
    "            model_kwargs = model_cfg['kwargs']\n",
    "            # the model object\n",
    "            model = model_cls.from_quantify(quantify, **model_kwargs)\n",
    "            \n",
    "            # add the model by column name\n",
    "            model_dict[src] = model\n",
    "        \n",
    "        # calculate the output size for dimention 1 (after concatenation)\n",
    "        self.out_features = sum(\n",
    "            list(model.out_features for src, model in model_dict.items()))\n",
    "        self.model_dict = model_dict\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = []\n",
    "        for src, model in self.model_dict.items():\n",
    "            # input data for column\n",
    "            src_input = inputs[src]\n",
    "            \n",
    "            # forward pass for column_model(column_data)\n",
    "            outputs.append(model(src_input))\n",
    "        # concat the results\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssembledModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        phase: Phase,\n",
    "        qdict: Dict[str, EntryModel],\n",
    "        entry_lr: LIST(options=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6], default=1e-4)=1e-4,\n",
    "        exit_lr: LIST(options=[1e-1, 1e-2, 1e-3, 1e-4, ], default=1e-3)=1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.entry_lr = entry_lr\n",
    "        self.exit_lr = exit_lr\n",
    "        self.entry_dict = EntryDict(phase, qdict)\n",
    "        exit_cfg = list(phase['y_models'].values())[0]\n",
    "        \n",
    "        self.exit_src = exit_cfg['src']\n",
    "        self.exit_kwargs = exit_cfg['kwargs']\n",
    "        exit_cls = EXIT_ALL[exit_cfg['model_name']]\n",
    "        \n",
    "        exit_quantify = qdict[self.exit_src]\n",
    "        \n",
    "        self.exit_part = exit_cls.from_quantify(\n",
    "            exit_quantify,self.entry_dict, **self.exit_kwargs)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        vec = self.entry_dict(inputs)\n",
    "        return self.exit_part(vec)\n",
    "    \n",
    "    def loss_step(self, inputs):\n",
    "        vec = self.entry_dict(inputs)\n",
    "        return self.exit_part.loss_step(vec, inputs[self.exit_src])\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        rt = self.loss_step(batch)\n",
    "        for k, v in rt.items():\n",
    "            if v.numel()==1:\n",
    "                self.log(f\"trn_{k}\", v)\n",
    "        return rt['loss']\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        rt = self.loss_step(batch)\n",
    "        for k, v in rt.items():\n",
    "            if v.numel()==1:\n",
    "                self.log(f\"val_{k}\", v)\n",
    "        return rt['loss']\n",
    "    \n",
    "    def configure_optimizers(self,):\n",
    "        param_groups = [\n",
    "            {\"params\":self.entry_dict.parameters(), \"lr\":self.entry_lr},\n",
    "            {\"params\":self.exit_part.parameters(), \"lr\":self.exit_lr},\n",
    "        ]\n",
    "        return torch.optim.Adam(param_groups)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(phase, qdict):\n",
    "    if \"y_models\" in phase:\n",
    "        y_models = phase[\"y_models\"]\n",
    "        if len(y_models)>1:\n",
    "            raise ValueError(\"Multiple targets are not supported by now\")\n",
    "        else:\n",
    "            return AssembledModel(phase, qdict)\n",
    "    else:\n",
    "        raise ValueError(\"phase must contain 'y_models' configuration for now\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_slug_name(phase):\n",
    "    xs = '-'.join(list(q['src'] for q in phase['quantify'] if q[\"x\"]))\n",
    "    ys = '-'.join(list(q['src'] for q in phase['quantify'] if q[\"x\"]==False))\n",
    "    return '_'.join([xs,'to',ys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vivid **name** for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainer(\n",
    "    phase,\n",
    "    project:STR(default=\"default\",) = \"default\",\n",
    "    tensorboard: BOOL(default=True)=True,\n",
    "    show_metric: BOOL(default=True)=True,\n",
    "    max_epochs: INT(min_=1, max_=200, default=5)=5,\n",
    "    use_gpu:BOOL(default=True)=True,\n",
    "):\n",
    "    if project=='default':\n",
    "        global PROJECT\n",
    "        if str(PROJECT)!=\"None\":\n",
    "            project = PROJECT\n",
    "        else:\n",
    "            project = \"./project\"\n",
    "    project = Path(project)\n",
    "    TASK_SLUG = make_slug_name(phase)\n",
    "    csv_logger = pl.loggers.CSVLogger(project/\"csv_log\", name = TASK_SLUG, )\n",
    "    loggers = [\n",
    "        csv_logger\n",
    "    ]\n",
    "    if tensorboard:\n",
    "        loggers.append(\n",
    "            pl.loggers.TensorBoardLogger(save_dir=project/'tensorboard', name=TASK_SLUG)\n",
    "        )\n",
    "    rt = dict(\n",
    "        max_epochs = max_epochs,\n",
    "        logger =loggers)\n",
    "    callbacks = []\n",
    "    if show_metric:\n",
    "        callbacks.append(\n",
    "            DataFrameMetricsCallback())\n",
    "        \n",
    "    rt.update({\"callbacks\":callbacks})\n",
    "    \n",
    "    if use_gpu:\n",
    "        rt.update(dict(gpus=1))\n",
    "#     rt.update(dict(\n",
    "#         auto_select_gpus=True,\n",
    "#     ))\n",
    "    return rt\n",
    "\n",
    "def run_training(phase, final_model, datamodule):\n",
    "    def set_trainer_callback(kwargs):\n",
    "        task_slug = phase['task_slug']\n",
    "        Flash.info(f\"Create trainer for task: {task_slug}\",key=\"Notice\")\n",
    "        trainer_kwargs = set_trainer(phase, **kwargs)\n",
    "        trainer = pl.Trainer(**trainer_kwargs)\n",
    "        Flash.success(\"Start training, this is not a drill!\",key=\"Alert!\")\n",
    "        trainer.fit(final_model, datamodule=datamodule)\n",
    "        return trainer\n",
    "    return set_trainer_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_enrich(**kwargs):\n",
    "    df = kwargs['df']\n",
    "    phase = kwargs['phase']\n",
    "    progress = kwargs['progress']\n",
    "    set_enrich(df=df, phase=phase)\n",
    "\n",
    "\n",
    "def step_quantify(**kwargs):\n",
    "    df = kwargs.get('df')\n",
    "    phase = kwargs.get('phase')\n",
    "    progress = kwargs.get('progress')\n",
    "    execute_enrich(df=df, phase=phase)\n",
    "    # creating dataset\n",
    "    ds = TaiChiDataset(df)\n",
    "    progress.kwargs['dataset'] = ds\n",
    "    # preview a row of data\n",
    "    display(HTML(f\"<h3>A row of data</h3>\"))\n",
    "\n",
    "    @interact\n",
    "    def show_row(idx=IntSlider(min=0, max=min(len(ds), 30))):\n",
    "        list_group_kv(ds[idx])()\n",
    "    choose_xy(progress=progress, df=df, phase=phase)\n",
    "\n",
    "\n",
    "def step_modeling(**kwargs):\n",
    "    df = kwargs.get('df')\n",
    "    phase = kwargs.get('phase')\n",
    "    progress = kwargs.get('progress')\n",
    "\n",
    "    qdict = execute_quantify(df=df, phase=phase)\n",
    "    progress.kwargs['qdict'] = qdict\n",
    "    set_datamodule(progress, df, qdict, phase)\n",
    "\n",
    "\n",
    "def step_training(**kwargs):\n",
    "    df = kwargs.get('df')\n",
    "    phase = kwargs.get('phase')\n",
    "    progress = kwargs.get('progress')\n",
    "    qdict = kwargs.get('qdict')\n",
    "    datamodule = kwargs.get('datamodule')\n",
    "\n",
    "    if (qdict is None) or (datamodule is None):\n",
    "        print(f\"Please finish last step first\")\n",
    "    final_model = create_model(phase, qdict)\n",
    "    save_phase()\n",
    "    TASK_SLUG = make_slug_name(phase)\n",
    "    phase['task_slug'] = TASK_SLUG\n",
    "    progress.kwargs['model'] = final_model\n",
    "    interact_intercept(set_trainer, \n",
    "                       run_training(\n",
    "                            phase, final_model, datamodule)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_MAP: Dict[str, Callable] = {\n",
    "    \"Enrich\": step_enrich,\n",
    "    \"Quantify\": step_quantify,\n",
    "    \"Model\": step_modeling,\n",
    "    \"Train\": step_training}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiLearn:\n",
    "    \"\"\"\n",
    "    A dataframe please\n",
    "    then we learn\n",
    "    \"\"\"\n",
    "    def __init__(self, df, phase):\n",
    "        self.progress = StepByStep(\n",
    "            STEPS_MAP, kwargs={\"df\":df, \"phase\":phase})\n",
    "        \n",
    "    def __call__(self):\n",
    "        self.progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load all the code above in one shot, the demo starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra helpers\n",
    "> These are helper function relate to the task, ```only``` to modify the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def df_creator_image_folder(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataframe ,\n",
    "    Which list all the image path under a system folder\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    files = []\n",
    "    formats = [\"jpg\", \"jpeg\", \"png\"]\n",
    "    for fmt in formats:\n",
    "        files.extend(path.rglob(f\"*.{fmt.lower()}\"))\n",
    "        files.extend(path.rglob(f\"*.{fmt.upper()}\"))\n",
    "    return pd.DataFrame({\"path\": files}).sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def noise():\n",
    "    return random.random()*.1\n",
    "\n",
    "\n",
    "def turn_bear_dataset_to_regression(base_df):\n",
    "    base_df[\"grizzly_score\"] = base_df['path'].apply(\n",
    "        lambda x: .9 + noise() if Path(x).parent.name == 'grizzly' else .1 + noise())\n",
    "    return base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAR_DATASET = HOME/\"Downloads\"/\"bear_dataset\"\n",
    "BEAR_DATASET = Path(\"/GCI/data/bear_dataset\")\n",
    "ROTTEN_TOMATOES = Path(\"/GCI/data/rttmt\")\n",
    "NETFLIX = Path(\"/GCI/data/nf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the following to run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Netflix üì∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Dick Johnson Is Dead</td>\n",
       "      <td>Kirsten Johnson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>September 25, 2021</td>\n",
       "      <td>2020</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>90 min</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>As her father nears the end of his life, filmm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Blood &amp; Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Mysteries</td>\n",
       "      <td>After crossing paths at a party, a Cape Town t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Ganglands</td>\n",
       "      <td>Julien Leclercq</td>\n",
       "      <td>Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Crime TV Shows, International TV Shows, TV Act...</td>\n",
       "      <td>To protect his family from a powerful drug lor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Jailbirds New Orleans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Docuseries, Reality TV</td>\n",
       "      <td>Feuds, flirtations and toilet talk go down amo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Kota Factory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...</td>\n",
       "      <td>India</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, Romantic TV Shows, TV ...</td>\n",
       "      <td>In a city of coaching centers known to train I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type                  title         director  \\\n",
       "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
       "1      s2  TV Show          Blood & Water              NaN   \n",
       "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
       "3      s4  TV Show  Jailbirds New Orleans              NaN   \n",
       "4      s5  TV Show           Kota Factory              NaN   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0                                                NaN  United States   \n",
       "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
       "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
       "3                                                NaN            NaN   \n",
       "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
       "\n",
       "           date_added  release_year rating   duration  \\\n",
       "0  September 25, 2021          2020  PG-13     90 min   \n",
       "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
       "2  September 24, 2021          2021  TV-MA   1 Season   \n",
       "3  September 24, 2021          2021  TV-MA   1 Season   \n",
       "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0                                      Documentaries   \n",
       "1    International TV Shows, TV Dramas, TV Mysteries   \n",
       "2  Crime TV Shows, International TV Shows, TV Act...   \n",
       "3                             Docuseries, Reality TV   \n",
       "4  International TV Shows, Romantic TV Shows, TV ...   \n",
       "\n",
       "                                         description  \n",
       "0  As her father nears the end of his life, filmm...  \n",
       "1  After crossing paths at a party, a Cape Town t...  \n",
       "2  To protect his family from a powerful drug lor...  \n",
       "3  Feuds, flirtations and toilet talk go down amo...  \n",
       "4  In a city of coaching centers known to train I...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = pd.read_csv(NETFLIX/\"netflix_titles.csv\")\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The bear üêª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>grizzly_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000166.jpg</td>\n",
       "      <td>0.930374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000080.jpg</td>\n",
       "      <td>0.962466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000154.jpg</td>\n",
       "      <td>0.154357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/GCI/data/bear_dataset/teddys/00000047.jpg</td>\n",
       "      <td>0.198507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000142.jpg</td>\n",
       "      <td>0.173941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000091.jpg</td>\n",
       "      <td>0.977294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000040.jpg</td>\n",
       "      <td>0.914690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>/GCI/data/bear_dataset/teddys/00000001.jpg</td>\n",
       "      <td>0.131970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>/GCI/data/bear_dataset/teddys/00000130.jpg</td>\n",
       "      <td>0.105197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000018.jpg</td>\n",
       "      <td>0.967689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  grizzly_score\n",
       "0    /GCI/data/bear_dataset/grizzly/00000166.jpg       0.930374\n",
       "1    /GCI/data/bear_dataset/grizzly/00000080.jpg       0.962466\n",
       "2      /GCI/data/bear_dataset/black/00000154.jpg       0.154357\n",
       "3     /GCI/data/bear_dataset/teddys/00000047.jpg       0.198507\n",
       "4      /GCI/data/bear_dataset/black/00000142.jpg       0.173941\n",
       "..                                           ...            ...\n",
       "517  /GCI/data/bear_dataset/grizzly/00000091.jpg       0.977294\n",
       "518  /GCI/data/bear_dataset/grizzly/00000040.jpg       0.914690\n",
       "519   /GCI/data/bear_dataset/teddys/00000001.jpg       0.131970\n",
       "520   /GCI/data/bear_dataset/teddys/00000130.jpg       0.105197\n",
       "521  /GCI/data/bear_dataset/grizzly/00000018.jpg       0.967689\n",
       "\n",
       "[522 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = df_creator_image_folder(BEAR_DATASET)\n",
    "base_df = turn_bear_dataset_to_regression(base_df)\n",
    "base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The rotten tomatoes üçÖ üé¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Nick Schager</td>\n",
       "      <td>False</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.250</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Bill Goodykoontz</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Jim Schembri</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Crammed with dragons, set-destroying fights an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Mark Adams</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mirror (UK)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108237</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Phil Villarreal</td>\n",
       "      <td>False</td>\n",
       "      <td>Arizona Daily Star</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>It might have worked better as a documentary, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108238</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Todd Gilchrist</td>\n",
       "      <td>False</td>\n",
       "      <td>IGN Movies</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>Bottle Shock feels more like an excuse to exer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108239</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Austin Kennedy</td>\n",
       "      <td>False</td>\n",
       "      <td>Sin Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2008-09-02</td>\n",
       "      <td>I was slightly involved towards the end, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108240</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Sean P. Means</td>\n",
       "      <td>False</td>\n",
       "      <td>Salt Lake Tribune</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2008-09-05</td>\n",
       "      <td>Flat, musty and with a hint of flopsweat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108241</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Pete Hammond</td>\n",
       "      <td>False</td>\n",
       "      <td>Hollywood.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2008-10-01</td>\n",
       "      <td>One of the year's most entertaining films.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108242 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rotten_tomatoes_link       critic_name  top_critic  \\\n",
       "0                 m/0814255      Ben McEachen       False   \n",
       "1                 m/0814255      Nick Schager       False   \n",
       "2                 m/0814255  Bill Goodykoontz        True   \n",
       "3                 m/0814255      Jim Schembri        True   \n",
       "4                 m/0814255        Mark Adams       False   \n",
       "...                     ...               ...         ...   \n",
       "108237       m/bottle_shock   Phil Villarreal       False   \n",
       "108238       m/bottle_shock    Todd Gilchrist       False   \n",
       "108239       m/bottle_shock    Austin Kennedy       False   \n",
       "108240       m/bottle_shock     Sean P. Means       False   \n",
       "108241       m/bottle_shock      Pete Hammond       False   \n",
       "\n",
       "                 publisher_name review_type  review_score review_date  \\\n",
       "0       Sunday Mail (Australia)       Fresh         0.700  2010-02-09   \n",
       "1                Slant Magazine      Rotten         0.250  2010-02-10   \n",
       "2              Arizona Republic       Fresh         0.700  2010-02-10   \n",
       "3           The Age (Australia)       Fresh         0.600  2010-02-10   \n",
       "4             Daily Mirror (UK)       Fresh         0.800  2010-02-10   \n",
       "...                         ...         ...           ...         ...   \n",
       "108237       Arizona Daily Star      Rotten         0.500  2008-08-29   \n",
       "108238               IGN Movies      Rotten         0.400  2008-08-29   \n",
       "108239             Sin Magazine      Rotten         0.625  2008-09-02   \n",
       "108240        Salt Lake Tribune      Rotten         0.500  2008-09-05   \n",
       "108241            Hollywood.com       Fresh         0.800  2008-10-01   \n",
       "\n",
       "                                           review_content  \n",
       "0       Whether audiences will get behind The Lightnin...  \n",
       "1       Harry Potter knockoffs don't come more transpa...  \n",
       "2       Percy Jackson isn't a great movie, but it's a ...  \n",
       "3       Crammed with dragons, set-destroying fights an...  \n",
       "4       This action-packed fantasy adventure, based on...  \n",
       "...                                                   ...  \n",
       "108237  It might have worked better as a documentary, ...  \n",
       "108238  Bottle Shock feels more like an excuse to exer...  \n",
       "108239  I was slightly involved towards the end, but t...  \n",
       "108240          Flat, musty and with a hint of flopsweat.  \n",
       "108241         One of the year's most entertaining films.  \n",
       "\n",
       "[108242 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the rotten tomatoes dataset, we are not using every line\n",
    "base_df = pd.read_csv(ROTTEN_TOMATOES/'critic_reviews.csv', nrows=200000)\n",
    "base_df = base_df[~base_df['review_score'].isna()].reset_index(drop=True)\n",
    "base_df = base_df[~base_df['review_content'].isna()].reset_index(drop=True)\n",
    "base_df = base_df[~base_df['critic_name'].isna()].reset_index(drop=True)\n",
    "\n",
    "base_df = base_df[base_df['review_score'].apply(lambda x: \"/\" in x)].reset_index(drop=True)\n",
    "\n",
    "base_df['review_score'] = base_df['review_score'].apply(eval)\n",
    "\n",
    "base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where the model & config is going to end up:\n",
    "a PROJECT folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = Path(os.environ['HOME'])\n",
    "# PROJECT = Path(\"./project\")\n",
    "# PROJECT = Path(\"./project/image_regression\")\n",
    "# PROJECT = Path(\"./project/rotten1\")\n",
    "# PROJECT = Path(\"./project/rotten_text\")\n",
    "PROJECT = Path(\"./project/netflix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the ```phase``` to track the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"quantify\": [\n",
      "    {\n",
      "      \"src\": \"country\",\n",
      "      \"x\": true,\n",
      "      \"kwargs\": {\n",
      "        \"min_frequency\": 1,\n",
      "        \"separator\": \",\"\n",
      "      },\n",
      "      \"quantify\": \"QuantifyMultiCategory\"\n",
      "    },\n",
      "    {\n",
      "      \"src\": \"listed_in\",\n",
      "      \"x\": false,\n",
      "      \"kwargs\": {\n",
      "        \"min_frequency\": 1,\n",
      "        \"separator\": \",\"\n",
      "      },\n",
      "      \"quantify\": \"QuantifyMultiCategory\"\n",
      "    },\n",
      "    {\n",
      "      \"src\": \"cast\",\n",
      "      \"x\": true,\n",
      "      \"kwargs\": {\n",
      "        \"min_frequency\": 1,\n",
      "        \"separator\": \",\"\n",
      "      },\n",
      "      \"quantify\": \"QuantifyMultiCategory\"\n",
      "    }\n",
      "  ],\n",
      "  \"batch_level\": {\n",
      "    \"valid_ratio\": 0.1,\n",
      "    \"batch_size\": 8,\n",
      "    \"shuffle\": true,\n",
      "    \"num_workers\": 0\n",
      "  },\n",
      "  \"x_models\": {\n",
      "    \"country\": {\n",
      "      \"model_name\": \"MultiCategoryEncoder\",\n",
      "      \"src\": \"country\",\n",
      "      \"kwargs\": {\n",
      "        \"embedding_dim\": 64\n",
      "      }\n",
      "    },\n",
      "    \"cast\": {\n",
      "      \"model_name\": \"MultiCategoryEncoder\",\n",
      "      \"src\": \"cast\",\n",
      "      \"kwargs\": {\n",
      "        \"embedding_dim\": 64\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"y_models\": {\n",
      "    \"listed_in\": {\n",
      "      \"model_name\": \"MultiCategoryTop\",\n",
      "      \"src\": \"listed_in\",\n",
      "      \"kwargs\": {}\n",
      "    }\n",
      "  },\n",
      "  \"task_slug\": \"description-country_to_listed_in\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "load_phase()\n",
    "# phase = Phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b293affdb4a947cabb7cf10d975cedf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='danger', description='1:Enrich', icon='cube', style=ButtonS‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e72b6d32f64bc087d20fbf8173bc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = TaiChiLearn(base_df, phase)\n",
    "learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase:{\n",
       "  \"quantify\": [\n",
       "    {\n",
       "      \"src\": \"country\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"min_frequency\": 1,\n",
       "        \"separator\": \",\"\n",
       "      },\n",
       "      \"quantify\": \"QuantifyMultiCategory\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"listed_in\",\n",
       "      \"x\": false,\n",
       "      \"kwargs\": {\n",
       "        \"min_frequency\": 1,\n",
       "        \"separator\": \",\"\n",
       "      },\n",
       "      \"quantify\": \"QuantifyMultiCategory\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"cast\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"min_frequency\": 1,\n",
       "        \"separator\": \",\"\n",
       "      },\n",
       "      \"quantify\": \"QuantifyMultiCategory\"\n",
       "    }\n",
       "  ],\n",
       "  \"batch_level\": {\n",
       "    \"valid_ratio\": 0.1,\n",
       "    \"batch_size\": 8,\n",
       "    \"shuffle\": true,\n",
       "    \"num_workers\": 0\n",
       "  },\n",
       "  \"x_models\": {\n",
       "    \"country\": {\n",
       "      \"model_name\": \"MultiCategoryEncoder\",\n",
       "      \"src\": \"country\",\n",
       "      \"kwargs\": {\n",
       "        \"embedding_dim\": 64\n",
       "      }\n",
       "    },\n",
       "    \"cast\": {\n",
       "      \"model_name\": \"MultiCategoryEncoder\",\n",
       "      \"src\": \"cast\",\n",
       "      \"kwargs\": {\n",
       "        \"embedding_dim\": 64\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"y_models\": {\n",
       "    \"listed_in\": {\n",
       "      \"model_name\": \"MultiCategoryTop\",\n",
       "      \"src\": \"listed_in\",\n",
       "      \"kwargs\": {}\n",
       "    }\n",
       "  },\n",
       "  \"task_slug\": \"country-cast_to_listed_in\"\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = learn.progress.kwargs['datamodule']\n",
    "model = learn.progress.kwargs['model']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321.051px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
