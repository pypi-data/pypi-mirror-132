{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UnpackAI Library Development Plan\n",
    "> What library should we be?\n",
    "This proposal, is more of a branding proposal, targeting people who's going to play with AI, from various back grounds.\n",
    "* That means, we're going to talk about how people view this library, how they think of ```pip install -Uqq unpackai``` like if I have dandroff recengtly and my mind just jump right into the headshoulders.\n",
    "* For ML, currently, the **jump** is about the following, this is not a throught marketing research, just quick examples from a deep learning practitioner:\n",
    "    * Try free structure quickly, do experiments: pytorch\n",
    "    * Goes to production, run model on edge devices, Tensorflow\n",
    "    * Play with GPU accelerated tensor calculation: Jax\n",
    "    * Play with tf but in simpler layer sense: Keras\n",
    "    * Transformer in clean code: Huggingface\n",
    "    * Visualize things with interactive features: Plotly\n",
    "    * Deploy model prototype: streamlit\n",
    "* Surely you think I fail to mention ```fastai```, this is where the **branding goes wrong**, fastai library is bounded tightly with the education. It's considered a good creation along side its famous course, after the education. Its product feature has many limitation: docs too brief, not supporting multi-device training, very limited numbers of callbacks went beyond Jeremy H's own teaching.\n",
    "* Most important of all, ```fastai``` isn't enjoyable to use, **it's just packing many things mentioned in the course**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we shouldn't be\n",
    "I know the course is life changing for me and I feel very grateful. But let's not be their library.\n",
    "\n",
    "### The pipeline wrapping plan\n",
    "It all started from a notebook, quite like a template notebook we have for the course. A notebook that achieves the data processing, model building, interpretation for a specific DL task.\n",
    "\n",
    "Then came the packaging part, we wrap **dozens of lines of codes**, which scares our kind students, into simple functions, or class.\n",
    "\n",
    "The wrapped functions are simple to use, to look at, it was executed in 1 line mostly. So friendly to our innocent students.\n",
    "\n",
    "This is what a python library is about, right? Wrap things into functions which can be further wraped into even less lines.\n",
    "\n",
    "It's nothing wrong about this approach at first. Some DL task, if need be, can be shrank into **less than 10 lines of codes.**\n",
    "* The 1st line load the data, \n",
    "* the 2nd line set how to transform data, \n",
    "* the 3rd line build/load the model, \n",
    "* the 4th line trained model.\n",
    "* the 5th line interpret the model in various ways\n",
    "\n",
    "Well the above do look like a decent **structure** to start with, then we pave out the tasks, different contributors take different tasks, can be developed in parallel, and we can have the agile/crum/kanban fun to track our progress!\n",
    "\n",
    "Even if we do this, we could build a useful product, no less.\n",
    "\n",
    "#### Bad side about pipeline wrapping plan\n",
    "So so many libraries are doing the same, from awesome people even. They usually end up to the following:\n",
    "* It's a mess of functions, among them many good functions but a mess. It ends up a branding disaster. (**There is no way to answer: what can you library do, in a slogan**)\n",
    "* A model zoo for a specific domain.\n",
    "* Wraping things up means less and less involvement from the user. The user will spend very little time play with the functions, and each function usually achieve very specific task. Actually I do believe there is a equilibrium like:\n",
    "$\\large{UserPlayHours = a * Task Transferability}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The salvation plan is somehow simpler at how we perceive the library:\n",
    "* A library that allows you experiment AI/DL for various tasks\n",
    "\n",
    "**BUT!!!**\n",
    "* Many module with in the pipeline should be dropdown-list/checkbox **Choosable**.\n",
    "* The **level of detail** we let them to play and choose, is the **level of the difficulty** we want them to enjoy\n",
    "\n",
    "### What is level of detail ?\n",
    "Level of details is the level of fuss we want user to focus on, this is the exact part fastai library got **WRONG**, which will explain most of our struggle so far:\n",
    "* It offers smooth/ easy pipelines, for newbies and business people even.\n",
    "* Any amount of reconfigure, is usually way too complicated for such audience\n",
    "* There is a **GAP** between the 2 points above, hence no room for playing\n",
    "\n",
    "#### Keras Example \n",
    "I started my AI journey with Keras, and I love keras by that time, because:\n",
    "* Keras plays with **layers**(eg. Linear, Convolution), its most strenth is at astracting details beneath this level, and let users play with layers. \n",
    "* I spent lots of time, having fun playing with layers\n",
    "* Aside from the things I have to redesign layer, I can deploy almost all kinds of models mentioned in any DL paper (𝑈𝑠𝑒𝑟𝑃𝑙𝑎𝑦𝐻𝑜𝑢𝑟𝑠=𝑎∗𝑇𝑎𝑠𝑘𝑇𝑟𝑎𝑛𝑠𝑓𝑒𝑟𝑎𝑏𝑖𝑙𝑖𝑡𝑦)\n",
    "\n",
    "#### Pytorch lightning example\n",
    "Well I moved on to the career team. I have to deal with layer level, I have to deal with different data/forward pipeline. PL is a good library because:\n",
    "* It allows me play with the things I mentioned, but save my energy on things like looping, logging, multidevice training detail etc.\n",
    "* If you see a training notebook built by PL, you'll see very little lines around training template.\n",
    "* You'll find about a lots of lines on the specifications you intend to be different.\n",
    "\n",
    ">The branding image of the examples are simple:\n",
    "* Keras: play TensorFlow in a concept of layers\n",
    "* Pytorch-Lightning: writting less template code\n",
    "\n",
    "#### Unpackai Example\n",
    "For our lib, I intend for them to focus on, exactly the same range of things we want people to learn:\n",
    "* choose the columns they intend to use, in what way\n",
    "* choose the data transformations\n",
    "* choose the loss, the model structure to use (not keras.layer, not nn.module)\n",
    "* hit run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of such example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interact_manual\n",
    "from forgebox.imports import *\n",
    "from forgebox.category import Category\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# for the purpose of easier developing\n",
    "# I'm using pytorch-lightning here\n",
    "# This is a questionable, tough and revokable dicision\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = Path(os.environ['HOME'])\n",
    "# PROJECT = Path(\"./project\")\n",
    "# PROJECT = Path(\"./project/image_regression\")\n",
    "# PROJECT = Path(\"./project/rotten1\")\n",
    "PROJECT = Path(\"./project/rotten_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's skip data download here, I mean it's download, we're not going to reinvent brilliant stuff around download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAR_DATASET = HOME/\"Downloads\"/\"bear_dataset\"\n",
    "BEAR_DATASET = Path(\"/GCI/data/bear_dataset\")\n",
    "ROTTEN_TOMATOES = Path(\"/GCI/data/rttmt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Everything starts with dataframe\n",
    "\n",
    "For fastai, everything starts from list, an **ItemList** to be specific. **ImageList** and **TextList** is [**ItemList**](https://fastai1.fast.ai/tutorial.itemlist.html) with some slight enhanced feature.```[🧂, 🏓, 🍷, 🐻]```\n",
    "\n",
    "For the clarity of education, or for simplecity as ultimate form of beauty, we use [**DataFrame**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) as starting point, ItemList in table format. In this way, every dataset has the same starting point, even the tabular data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_creator_image_folder(path: Path)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataframe ,\n",
    "    Which list all the image path under a system folder\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    files = []\n",
    "    formats = [\"jpg\",\"jpeg\",\"png\"]\n",
    "    for fmt in formats:\n",
    "        files.extend(path.rglob(f\"*.{fmt.lower()}\"))\n",
    "        files.extend(path.rglob(f\"*.{fmt.upper()}\"))\n",
    "    return pd.DataFrame({\"path\":files}).sample(frac=1.).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase/ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Callable, Any, Tuple\n",
    "from torchvision import transforms as tfm\n",
    "from PIL import Image\n",
    "from forgebox.html import DOM\n",
    "from ipywidgets import VBox, HBox, HTML\n",
    "\n",
    "from ipywidgets import (\n",
    "    Text, Textarea, IntSlider, FloatSlider, SelectMultiple, Dropdown, Checkbox,\n",
    "    Layout, Button\n",
    ")\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Phase:\n",
    "    \"\"\"\n",
    "    A configuration management mechanism\n",
    "    \"\"\"\n",
    "    is_phase = True\n",
    "    def __init__(self, **kwargs):\n",
    "        self.config = dict()\n",
    "        self.config.update(kwargs)\n",
    "        \n",
    "    def __setitem__(self, k, v):\n",
    "        self.config[k] = v\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        return self.config[k]\n",
    "    \n",
    "    def __contains__(self, k):\n",
    "        return k in self.config\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.get_data(self.config)\n",
    "    \n",
    "    def get_data(self, raw):\n",
    "        \"\"\"\n",
    "        Reconstruct back to dict or list or value format\n",
    "        \"\"\"\n",
    "        if hasattr(raw,\"is_phase\"):\n",
    "            return raw.get_data(raw.config)\n",
    "        if type(raw) == list:\n",
    "            raw = list(self.get_data(i) for i in raw)\n",
    "            return raw\n",
    "        if type(raw) == dict:\n",
    "            for k, v in raw.items():\n",
    "                raw[k] = self.get_data(v)\n",
    "            return raw\n",
    "        return raw\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps(self(), indent=2)\n",
    "    \n",
    "    def __repr__(self,):\n",
    "        return f\"Phase:{self}\"\n",
    "    \n",
    "\n",
    "# class EnrichPhase(Phase):\n",
    "#     def __init__(self, *steps):\n",
    "#         super().__init__()\n",
    "#         self.config['steps'] = []\n",
    "#         for step in steps:\n",
    "#             checked = self.check_step(step)\n",
    "#             if checked:\n",
    "#                 self.config['steps'].append(checked)\n",
    "                \n",
    "#     def new_step(self, process, dst:str, src: str=None):\n",
    "#         self.config['steps'].append({\n",
    "#             \"process\":process,\n",
    "#             \"src\":src,\n",
    "#             \"dst\":dst\n",
    "#         })\n",
    "    \n",
    "#     def check_step(self,step):\n",
    "#         return step\n",
    "    \n",
    "def save_phase():\n",
    "    global phase\n",
    "    global PROJECT\n",
    "    PROJECT = Path(PROJECT)\n",
    "    PROJECT.mkdir(exist_ok=True, parents=True)\n",
    "    with open(PROJECT/\"phase.json\", \"w\") as f:\n",
    "        f.write(str(phase))\n",
    "        \n",
    "def load_phase():\n",
    "    global phase\n",
    "    global PROJECT\n",
    "    PROJECT = Path(PROJECT)\n",
    "    PROJECT.mkdir(exist_ok=True, parents=True)\n",
    "    if (PROJECT/\"phase.json\").exists():\n",
    "        with open(PROJECT/\"phase.json\", \"r\") as f:\n",
    "            phase = Phase(**json.loads(f.read()))\n",
    "            print(phase)\n",
    "    else:\n",
    "        phase = Phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widget Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More or less\n",
    "And editable list within jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoreOrLess(VBox):\n",
    "    \"\"\"\n",
    "    Interactive list\n",
    "    You can add item to the list\n",
    "    Each added item has a remove button to remove such item\n",
    "    \"\"\"\n",
    "    def __init__(self, data_list: List[Any] = []):\n",
    "        super().__init__([])\n",
    "        for data in data_list:\n",
    "            self+data\n",
    "\n",
    "    def create_line(self, data):\n",
    "        children = list(self.children)\n",
    "        children.append(self.new_line(data))\n",
    "        self.children = children\n",
    "\n",
    "    @staticmethod\n",
    "    def data_to_dom(data):\n",
    "        return HTML(json.dumps(data))\n",
    "\n",
    "    def new_line(self, data) -> HBox:\n",
    "        del_btn = Button(description=\"Remove\", icon=\"trash\")\n",
    "        del_btn.button_style = 'danger'\n",
    "        hbox = HBox([del_btn, self.data_to_dom(data)])\n",
    "        hbox.data = data\n",
    "\n",
    "        def remove_hbox():\n",
    "            children = list(self.children)\n",
    "            for i, c in enumerate(children):\n",
    "                if id(c) == id(hbox):\n",
    "                    children.remove(c)\n",
    "            self.children = children\n",
    "        del_btn.click = remove_hbox\n",
    "        return hbox\n",
    "\n",
    "    def __add__(self, data):\n",
    "        self.create_line(data)\n",
    "        return self\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Return the data of this list\n",
    "        \"\"\"\n",
    "        return list(x.data for x in self.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = MoreOrLess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eede3b4e8fb44cb8d17a90e053f5be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MoreOrLess(children=(HBox(children=(Button(button_style='danger', description='Remove', icon='trash', style=Bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mol+{\"hello\":\"Hello\"}\n",
    "mol+{\"may I\":\"yes\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### typings for interactives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typing for interactive details\n",
    "```self()``` will create widgets automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveTyping:\n",
    "    \"\"\"\n",
    "    Typing for interactive details\n",
    "    self.__call__() will create widgets directly\n",
    "    \"\"\"\n",
    "    name = \"anything\"\n",
    "    is_typing = True\n",
    "\n",
    "    def solid(self, default) -> None:\n",
    "        \"\"\"\n",
    "        Reset default value\n",
    "        \"\"\"\n",
    "        if default is not None:\n",
    "            self.default = default\n",
    "\n",
    "\n",
    "class INT(InteractiveTyping):\n",
    "    def __init__(self, min_: int = 0, max_: int = 10, step: int = 1, default: int = None):\n",
    "        self.max_ = max_\n",
    "        self.min_ = min_\n",
    "        self.step = step\n",
    "        self.default = default if default is not None else 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"int[{self.min_}-{self.max_}, :{self.step}]={self.default}\"\n",
    "\n",
    "    def __call__(self, default: int = None):\n",
    "        self.solid(default)\n",
    "        return IntSlider(\n",
    "            value=self.default,\n",
    "            min=self.min_,\n",
    "            max=self.max_,\n",
    "            step=self.step,\n",
    "        )\n",
    "\n",
    "\n",
    "class BOOL(InteractiveTyping):\n",
    "    def __init__(self, name:str=\"\", default: bool = True,):\n",
    "        self.default = default\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"bool={self.default}\"\n",
    "\n",
    "    def __call__(self, default: bool = None) -> Checkbox:\n",
    "        self.solid(default)\n",
    "        return Checkbox(value=self.default, description=self.name)\n",
    "\n",
    "\n",
    "class FLOAT(InteractiveTyping):\n",
    "    def __init__(self, min_: int = -1., max_: int = 1., step: int = .01, default: int = None):\n",
    "        self.max_ = max_\n",
    "        self.min_ = min_\n",
    "        self.step = step\n",
    "        self.default = default if default is not None else 0.01\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"float[{self.min_}-{self.max_}, :{self.step}]={self.default}\"\n",
    "\n",
    "    def __call__(self, default: int = None):\n",
    "        self.solid(default)\n",
    "        return FloatSlider(\n",
    "            value=self.default,\n",
    "            min=self.min_,\n",
    "            max=self.max_,\n",
    "            step=self.step,\n",
    "        )\n",
    "\n",
    "\n",
    "class STR(InteractiveTyping):\n",
    "    \"\"\"\n",
    "    String object\n",
    "    will create text or textarea\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, default: str = None, use_area: bool = False):\n",
    "        \"\"\"\n",
    "        use_area: do we use Textarea, if False,we use Text\n",
    "        \"\"\"\n",
    "        self.default = \"\" if default is None else default\n",
    "        self.use_area = use_area\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"str='{self.default}'\"\n",
    "\n",
    "    def __call__(self, default: str = None):\n",
    "        self.solid(default)\n",
    "        if self.use_area:\n",
    "            return Textarea(value=self.default, layout=Layout(width=\"80%\"))\n",
    "        return Text(value=self.default)\n",
    "\n",
    "\n",
    "class LIST(InteractiveTyping):\n",
    "    \"\"\"\n",
    "    dropdown list type or multiselection type\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, options: List[Any] = [], default: Any = None, multi: bool = False):\n",
    "        \"\"\"\n",
    "        if multi: default should be iterable\n",
    "        else: default should be one of the option\n",
    "        \"\"\"\n",
    "        self.options = options\n",
    "        self.default = default\n",
    "        self.multi = multi\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.multi:\n",
    "            size = f\"[0-{self.default}]/{len(self.options)}\"\n",
    "        else:\n",
    "            size = f\"1/{len(self.options)}\"\n",
    "        return f\"list,{size}\"\n",
    "\n",
    "    def __call__(self, default: Any = None):\n",
    "        self.solid(default)\n",
    "        if self.multi:\n",
    "            inter = SelectMultiple(options=self.options)\n",
    "        else:\n",
    "            inter = Dropdown(options=self.options)\n",
    "\n",
    "        if self.default is not None:\n",
    "            # if multi: default should be iterable\n",
    "            # else: default should be one of the option\n",
    "            inter.value = self.default\n",
    "        return inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original ```interact_manual``` isn't powerful enough for this situation, so the following is a more flexible way to decorate an interactive function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveAnnotations:\n",
    "    \"\"\"\n",
    "    Build interactive based on the info of function's ```__annotations__```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, func: Callable,\n",
    "        icon: str = \"rocket\",\n",
    "        description: str = 'Run',\n",
    "        button_style='primary'\n",
    "    ):\n",
    "        self.func = func\n",
    "        self.icon = icon\n",
    "        self.button_style = button_style\n",
    "        self.description = description\n",
    "        self.build_vbox(func)\n",
    "\n",
    "    @classmethod\n",
    "    def on(\n",
    "        cls,\n",
    "        callback: Callable,\n",
    "        icon: str = 'rocket',\n",
    "        description: str = 'Run',\n",
    "        button_style: str = 'primary'\n",
    "    ) -> Callable:\n",
    "        \"\"\"\n",
    "        Use this class as a decorator\n",
    "        @InteractiveAnnotation.on(callback)\n",
    "        def target_func(a:STR(), b:INT()=1):\n",
    "            ...\n",
    "        \"\"\"\n",
    "        def decorator(func: Callable):\n",
    "            obj = cls(\n",
    "                func,\n",
    "                icon=icon,\n",
    "                description=description,\n",
    "                button_style=button_style\n",
    "            )\n",
    "            display(obj.vbox)\n",
    "            obj.register_callback(callback=callback)\n",
    "            return func\n",
    "        return decorator\n",
    "\n",
    "    def build_vbox(self, func: Callable):\n",
    "        row_list = []\n",
    "        self.fields = dict()\n",
    "        for k, v in func.__annotations__.items():\n",
    "            if hasattr(v, \"is_typing\") == False:\n",
    "                continue\n",
    "            widget = v()\n",
    "            widget.description = k\n",
    "            row_list.append(widget)\n",
    "            self.fields.update({k: widget})\n",
    "\n",
    "        # final button\n",
    "        self.final_btn = Button(\n",
    "            description=self.description,\n",
    "            icon=self.icon,\n",
    "        )\n",
    "        self.final_btn.button_style = self.button_style\n",
    "        row_list.append(self.final_btn)\n",
    "\n",
    "        # create interactive\n",
    "        self.vbox = VBox(row_list)\n",
    "        return self.vbox\n",
    "\n",
    "    def register_callback(\n",
    "        self,\n",
    "        callback: Callable\n",
    "    ) -> None:\n",
    "        def run_callback():\n",
    "            kwargs = self()\n",
    "            callback(kwargs)\n",
    "        self.final_btn.click = run_callback\n",
    "\n",
    "    def __call__(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        extract interactive data values\n",
    "        \"\"\"\n",
    "        rt = dict()\n",
    "        for k, widget in self.fields.items():\n",
    "            rt.update({k: widget.get_interact_value()})\n",
    "        return rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test callback & decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2633a4354cb240e18f7b1fb4c35d5df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='a'), IntSlider(value=1, description='b', max=10), Button(button_sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_stuff(kwargs):\n",
    "    print(kwargs)\n",
    "\n",
    "@InteractiveAnnotations.on(print_stuff, \"flask\", \"test\", button_style=\"warning\")\n",
    "def some_func(e, a:STR(), b:INT()=2, d=3):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142c6e3646334413b027f5cd10a44e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='RGB')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STR('RGB')()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercept interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kwargs(kwargs):\n",
    "    print(kwargs)\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def reconfig_manual_interact(\n",
    "    widget,\n",
    "    description: str = \"Create\",\n",
    "    button_style: str = \"primary\",\n",
    "    icon: str = \"plus\"\n",
    ") -> Button:\n",
    "    \"\"\"\n",
    "    reconfigure the button of interactive features\n",
    "    \"\"\"\n",
    "    btn = None\n",
    "    for w in widget.children:\n",
    "        if type(w) == Button:\n",
    "            btn = w\n",
    "            break\n",
    "    btn.description = description\n",
    "    btn.button_style = button_style\n",
    "    btn.icon = icon\n",
    "    return btn\n",
    "\n",
    "\n",
    "def interact_intercept(\n",
    "    func:Callable,\n",
    "    result_cb: Callable = print_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Initialize a class with interactive features\n",
    "    \"\"\"\n",
    "    annotations = func.__annotations__\n",
    "    defaults = func.__defaults__\n",
    "    kwargs = dict()\n",
    "    if defaults is not None:\n",
    "        for (k, typing), default in zip(annotations.items(), defaults):\n",
    "            kwargs.update({k: typing(default)})\n",
    "    obj = dict()\n",
    "\n",
    "    def fillin_init(**kwargs):\n",
    "        obj.update({\n",
    "            \"kwargs\": kwargs,\n",
    "        })\n",
    "    f = interact_manual(fillin_init, **kwargs)\n",
    "\n",
    "    btn = reconfig_manual_interact(f.widget)\n",
    "\n",
    "    if btn is not None:\n",
    "        original = btn.click\n",
    "\n",
    "        def new_click_event():\n",
    "            original()\n",
    "            return result_cb(obj['kwargs'])\n",
    "        btn.click = new_click_event\n",
    "\n",
    "    return obj, f\n",
    "\n",
    "def init_interact(cls, result_cb: Callable = print_kwargs):\n",
    "    return interact_intercept(cls.__init__, result_cb=result_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich columns (feature transformation, label extraction)\n",
    "After this step, there will only be **MORE** column ➕"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enrich:\n",
    "    \"\"\"\n",
    "    Enrich Base Class\n",
    "    Some default attributes\n",
    "    - is_enrich = True\n",
    "    - typing = None # output typing\n",
    "    - multi_cols = False # use multi-column as input\n",
    "    - prefer = None\n",
    "    - lazy = False  # shall we execute enrichment only through the iteration\n",
    "    - src = None # source column\n",
    "    \"\"\"\n",
    "    is_enrich = True\n",
    "    typing = None # output typing\n",
    "    multi_cols = False # use multi-column as input\n",
    "    prefer = None\n",
    "    lazy = False  # shall we execute enrichment only through the iteration\n",
    "    src = None # source column\n",
    "\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __call__(self, row):\n",
    "        return row\n",
    "    \n",
    "    def rowing(self, row):\n",
    "        if self.multi_cols:\n",
    "            return self(row)\n",
    "        else:\n",
    "            return self(row[self.src])\n",
    "\n",
    "\n",
    "class EnrichImage(Enrich):\n",
    "    \"\"\"\n",
    "    Create Image column from image path column\n",
    "    \"\"\"\n",
    "    prefer = \"QuantifyImage\"\n",
    "    typing = Image\n",
    "    lazy = True\n",
    "    \n",
    "\n",
    "    def __init__(\n",
    "        self, convert: STR(\"RGB\") = \"RGB\",\n",
    "        size: LIST(options=[28, 128, 224, 256, 512], default=224) = 224,\n",
    "    ):\n",
    "        self.convert = convert\n",
    "        self.size = size\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"[Image:{self.size}]\"\n",
    "\n",
    "    def __call__(self, x):\n",
    "        img = Image.open(x).convert(self.convert)\n",
    "        img = img.resize((self.size, self.size))\n",
    "        return img\n",
    "\n",
    "\n",
    "class ParentAsLabel(Enrich):\n",
    "    typing = str\n",
    "    prefer = \"QuantifyCategory\"\n",
    "    def __call__(self, path: Path,) -> str:\n",
    "        \"\"\"\n",
    "        Use parent folder name as label\n",
    "        \"\"\"\n",
    "        return Path(path).parent.name\n",
    "    \n",
    "ENRICHMENTS = dict(\n",
    "    EnrichImage=EnrichImage,\n",
    "    ParentAsLabel=ParentAsLabel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de464c32ddfa47f2815c5f23f18f8089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='RGB', description='convert'), Dropdown(description='size', index=2, options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj,f = init_interact(EnrichImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interact creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Nick Schager</td>\n",
       "      <td>False</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.250</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Bill Goodykoontz</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Jim Schembri</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Crammed with dragons, set-destroying fights an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Mark Adams</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mirror (UK)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109463</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Phil Villarreal</td>\n",
       "      <td>False</td>\n",
       "      <td>Arizona Daily Star</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>It might have worked better as a documentary, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109464</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Todd Gilchrist</td>\n",
       "      <td>False</td>\n",
       "      <td>IGN Movies</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>Bottle Shock feels more like an excuse to exer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109465</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Austin Kennedy</td>\n",
       "      <td>False</td>\n",
       "      <td>Sin Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2008-09-02</td>\n",
       "      <td>I was slightly involved towards the end, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109466</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Sean P. Means</td>\n",
       "      <td>False</td>\n",
       "      <td>Salt Lake Tribune</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2008-09-05</td>\n",
       "      <td>Flat, musty and with a hint of flopsweat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109467</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Pete Hammond</td>\n",
       "      <td>False</td>\n",
       "      <td>Hollywood.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2008-10-01</td>\n",
       "      <td>One of the year's most entertaining films.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109468 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rotten_tomatoes_link       critic_name  top_critic  \\\n",
       "0                 m/0814255      Ben McEachen       False   \n",
       "1                 m/0814255      Nick Schager       False   \n",
       "2                 m/0814255  Bill Goodykoontz        True   \n",
       "3                 m/0814255      Jim Schembri        True   \n",
       "4                 m/0814255        Mark Adams       False   \n",
       "...                     ...               ...         ...   \n",
       "109463       m/bottle_shock   Phil Villarreal       False   \n",
       "109464       m/bottle_shock    Todd Gilchrist       False   \n",
       "109465       m/bottle_shock    Austin Kennedy       False   \n",
       "109466       m/bottle_shock     Sean P. Means       False   \n",
       "109467       m/bottle_shock      Pete Hammond       False   \n",
       "\n",
       "                 publisher_name review_type  review_score review_date  \\\n",
       "0       Sunday Mail (Australia)       Fresh         0.700  2010-02-09   \n",
       "1                Slant Magazine      Rotten         0.250  2010-02-10   \n",
       "2              Arizona Republic       Fresh         0.700  2010-02-10   \n",
       "3           The Age (Australia)       Fresh         0.600  2010-02-10   \n",
       "4             Daily Mirror (UK)       Fresh         0.800  2010-02-10   \n",
       "...                         ...         ...           ...         ...   \n",
       "109463       Arizona Daily Star      Rotten         0.500  2008-08-29   \n",
       "109464               IGN Movies      Rotten         0.400  2008-08-29   \n",
       "109465             Sin Magazine      Rotten         0.625  2008-09-02   \n",
       "109466        Salt Lake Tribune      Rotten         0.500  2008-09-05   \n",
       "109467            Hollywood.com       Fresh         0.800  2008-10-01   \n",
       "\n",
       "                                           review_content  \n",
       "0       Whether audiences will get behind The Lightnin...  \n",
       "1       Harry Potter knockoffs don't come more transpa...  \n",
       "2       Percy Jackson isn't a great movie, but it's a ...  \n",
       "3       Crammed with dragons, set-destroying fights an...  \n",
       "4       This action-packed fantasy adventure, based on...  \n",
       "...                                                   ...  \n",
       "109463  It might have worked better as a documentary, ...  \n",
       "109464  Bottle Shock feels more like an excuse to exer...  \n",
       "109465  I was slightly involved towards the end, but t...  \n",
       "109466          Flat, musty and with a hint of flopsweat.  \n",
       "109467         One of the year's most entertaining films.  \n",
       "\n",
       "[109468 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base_df = df_creator_image_folder(BEAR_DATASET)\n",
    "\n",
    "# the rotten tomatoes dataset, we are not using every line\n",
    "base_df = pd.read_csv(ROTTEN_TOMATOES/'critic_reviews.csv', nrows=200000)\n",
    "base_df = base_df[~base_df['review_score'].isna()].reset_index(drop=True)\n",
    "base_df = base_df[~base_df['review_content'].isna()].reset_index(drop=True)\n",
    "base_df = base_df[base_df['review_score'].apply(lambda x: \"/\" in x)].reset_index(drop=True)\n",
    "\n",
    "base_df['review_score'] = base_df['review_score'].apply(eval)\n",
    "\n",
    "base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Enrich 🎸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_enrich(df):\n",
    "    global phase\n",
    "    DOM(f\"{len(df)} rows of data, example table\", \"h3\")()\n",
    "    display(df.sample(5))\n",
    "    display(HTML(\"<hr>\"))\n",
    "\n",
    "    def setting_col():\n",
    "        enrich_data_list = phase['enrich'] if 'enrich' in phase else []\n",
    "        enrich_box = MoreOrLess(enrich_data_list)\n",
    "        display(enrich_box)\n",
    "\n",
    "        \n",
    "        def set_enrich_(src=[\"[all_columns]\", ]+list(df.columns)):\n",
    "            DOM(f\"Setting up column enrich: {src}\", \"h4\")()\n",
    "            if src == \"[all_columns]\":\n",
    "                display(df.head(3))\n",
    "            else:\n",
    "                display(df[[src, ]].head(3))\n",
    "\n",
    "            def choose_enrich(dst=\"\", enrich=ENRICHMENTS):\n",
    "                DOM(f\"Source: {src}, Destination: {dst}, for {enrich.__name__}\", \"h4\")(\n",
    "                )\n",
    "                DOM(f\"{enrich.__doc__}\", \"quote\")()\n",
    "\n",
    "                def result_callback(kwargs):\n",
    "                    extra = {\"src\": src, \"dst\": dst,\n",
    "                                \"kwargs\": kwargs, \"enrich\": enrich.__name__}\n",
    "                    enrich_box+extra\n",
    "                    phase['enrich'] = enrich_box.get_data()\n",
    "                obj, decoed_func = init_interact(enrich, result_callback)\n",
    "            choose_enrich_widget = interact_manual(choose_enrich).widget\n",
    "            reconfig_manual_interact(\n",
    "                choose_enrich_widget,\n",
    "                description=\"Choose\", button_style='warning')\n",
    "        set_enrich_widget = interact_manual(set_enrich_).widget\n",
    "        reconfig_manual_interact(set_enrich_widget, button_style='warning')\n",
    "    setting_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>109468 rows of data, example table</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15348</th>\n",
       "      <td>m/1028564-guardian</td>\n",
       "      <td>Matt Brunson</td>\n",
       "      <td>False</td>\n",
       "      <td>Creative Loafing</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>As far as flying nannies go, Jenny Seagrove's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22793</th>\n",
       "      <td>m/1105979-brothers</td>\n",
       "      <td>Steve Rhodes</td>\n",
       "      <td>False</td>\n",
       "      <td>Internet Reviews</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2001-03-21</td>\n",
       "      <td>It isn't much of a movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78302</th>\n",
       "      <td>m/arizona_2018</td>\n",
       "      <td>Jared Mobarak</td>\n",
       "      <td>False</td>\n",
       "      <td>Jaredmobarak.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>It's stupid, exploits the housing crisis as fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59161</th>\n",
       "      <td>m/accepted</td>\n",
       "      <td>Chris Cabin</td>\n",
       "      <td>False</td>\n",
       "      <td>Filmcritic.com</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2006-08-28</td>\n",
       "      <td>expect an uneasy feeling of recycling.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32873</th>\n",
       "      <td>m/1178913-1178913-you_kill_me</td>\n",
       "      <td>Rob Thomas</td>\n",
       "      <td>False</td>\n",
       "      <td>Capital Times (Madison, WI)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2007-07-13</td>\n",
       "      <td>When Frank stands up at a meeting and confesse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rotten_tomatoes_link    critic_name  top_critic  \\\n",
       "15348             m/1028564-guardian   Matt Brunson       False   \n",
       "22793             m/1105979-brothers   Steve Rhodes       False   \n",
       "78302                 m/arizona_2018  Jared Mobarak       False   \n",
       "59161                     m/accepted    Chris Cabin       False   \n",
       "32873  m/1178913-1178913-you_kill_me     Rob Thomas       False   \n",
       "\n",
       "                    publisher_name review_type  review_score review_date  \\\n",
       "15348             Creative Loafing      Rotten          0.50  2016-01-23   \n",
       "22793             Internet Reviews      Rotten          0.50  2001-03-21   \n",
       "78302             Jaredmobarak.com       Fresh          0.60  2018-08-28   \n",
       "59161               Filmcritic.com      Rotten          0.40  2006-08-28   \n",
       "32873  Capital Times (Madison, WI)       Fresh          0.75  2007-07-13   \n",
       "\n",
       "                                          review_content  \n",
       "15348  As far as flying nannies go, Jenny Seagrove's ...  \n",
       "22793                          It isn't much of a movie.  \n",
       "78302  It's stupid, exploits the housing crisis as fo...  \n",
       "59161             expect an uneasy feeling of recycling.  \n",
       "32873  When Frank stands up at a meeting and confesse...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876540e90de646feb09bcd27f23ab4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<hr>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bd6444dd144bd5b5194bc11277f615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MoreOrLess()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fe5680aa0a4abcb32b1047962b3866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='src', options=('[all_columns]', 'rotten_tomatoes_link', 'critic_na…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_enrich(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase:{}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute enrichment\n",
    "> apply the enrichment settings to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_enrich(\n",
    "    df: pd.DataFrame, phase:Phase\n",
    "):\n",
    "    if 'enrich' not in phase:\n",
    "        return df\n",
    "    for en_conf in tqdm(phase[\"enrich\"], leave=False):\n",
    "        enrich_name = en_conf['enrich']\n",
    "        enrich_cls = ENRICHMENTS[enrich_name]\n",
    "        kwargs = en_conf['kwargs']\n",
    "        src = en_conf['src']\n",
    "        dst = en_conf['dst']\n",
    "        # The class with lazy loading, will only \n",
    "        # call the class only if necessary\n",
    "        if enrich_cls.lazy:\n",
    "            obj = enrich_cls(**kwargs)\n",
    "            obj.src = src\n",
    "            df[dst] = obj\n",
    "        # The class without lazy loading\n",
    "        # create the column now\n",
    "        else:\n",
    "            obj = enrich_cls(**kwargs)\n",
    "            if src==\"[all_columns]\":\n",
    "                df[dst] = df.apply(obj, axis=1)\n",
    "            else:\n",
    "                df[dst] = df[src].apply(obj)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see? more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Nick Schager</td>\n",
       "      <td>False</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.250</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Bill Goodykoontz</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Jim Schembri</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Crammed with dragons, set-destroying fights an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Mark Adams</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mirror (UK)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109463</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Phil Villarreal</td>\n",
       "      <td>False</td>\n",
       "      <td>Arizona Daily Star</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>It might have worked better as a documentary, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109464</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Todd Gilchrist</td>\n",
       "      <td>False</td>\n",
       "      <td>IGN Movies</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>Bottle Shock feels more like an excuse to exer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109465</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Austin Kennedy</td>\n",
       "      <td>False</td>\n",
       "      <td>Sin Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2008-09-02</td>\n",
       "      <td>I was slightly involved towards the end, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109466</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Sean P. Means</td>\n",
       "      <td>False</td>\n",
       "      <td>Salt Lake Tribune</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2008-09-05</td>\n",
       "      <td>Flat, musty and with a hint of flopsweat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109467</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Pete Hammond</td>\n",
       "      <td>False</td>\n",
       "      <td>Hollywood.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2008-10-01</td>\n",
       "      <td>One of the year's most entertaining films.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109468 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rotten_tomatoes_link       critic_name  top_critic  \\\n",
       "0                 m/0814255      Ben McEachen       False   \n",
       "1                 m/0814255      Nick Schager       False   \n",
       "2                 m/0814255  Bill Goodykoontz        True   \n",
       "3                 m/0814255      Jim Schembri        True   \n",
       "4                 m/0814255        Mark Adams       False   \n",
       "...                     ...               ...         ...   \n",
       "109463       m/bottle_shock   Phil Villarreal       False   \n",
       "109464       m/bottle_shock    Todd Gilchrist       False   \n",
       "109465       m/bottle_shock    Austin Kennedy       False   \n",
       "109466       m/bottle_shock     Sean P. Means       False   \n",
       "109467       m/bottle_shock      Pete Hammond       False   \n",
       "\n",
       "                 publisher_name review_type  review_score review_date  \\\n",
       "0       Sunday Mail (Australia)       Fresh         0.700  2010-02-09   \n",
       "1                Slant Magazine      Rotten         0.250  2010-02-10   \n",
       "2              Arizona Republic       Fresh         0.700  2010-02-10   \n",
       "3           The Age (Australia)       Fresh         0.600  2010-02-10   \n",
       "4             Daily Mirror (UK)       Fresh         0.800  2010-02-10   \n",
       "...                         ...         ...           ...         ...   \n",
       "109463       Arizona Daily Star      Rotten         0.500  2008-08-29   \n",
       "109464               IGN Movies      Rotten         0.400  2008-08-29   \n",
       "109465             Sin Magazine      Rotten         0.625  2008-09-02   \n",
       "109466        Salt Lake Tribune      Rotten         0.500  2008-09-05   \n",
       "109467            Hollywood.com       Fresh         0.800  2008-10-01   \n",
       "\n",
       "                                           review_content  \n",
       "0       Whether audiences will get behind The Lightnin...  \n",
       "1       Harry Potter knockoffs don't come more transpa...  \n",
       "2       Percy Jackson isn't a great movie, but it's a ...  \n",
       "3       Crammed with dragons, set-destroying fights an...  \n",
       "4       This action-packed fantasy adventure, based on...  \n",
       "...                                                   ...  \n",
       "109463  It might have worked better as a documentary, ...  \n",
       "109464  Bottle Shock feels more like an excuse to exer...  \n",
       "109465  I was slightly involved towards the end, but t...  \n",
       "109466          Flat, musty and with a hint of flopsweat.  \n",
       "109467         One of the year's most entertaining films.  \n",
       "\n",
       "[109468 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_enrich(base_df, phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def noise():\n",
    "    return random.random()*.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df[\"grizzly_score\"] = base_df['bear_kind'].apply(\n",
    "    lambda x: .9 +noise()  if x=='grizly' else .1+noise())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify: Choose columns as X and Y, put them into number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIZE_DIMENSION:\n",
    "    pass\n",
    "\n",
    "class BATCH_SIZE(SIZE_DIMENSION):\n",
    "    def __repr__(self): return f\"BATCH_SIZE\"\n",
    "\n",
    "class SEQUENCE_SIZE(SIZE_DIMENSION):\n",
    "    pass\n",
    "\n",
    "class IMAGE_SIZE(SIZE_DIMENSION):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Quantify:\n",
    "    is_quantify = True\n",
    "    \"\"\"\n",
    "    # From all things to number\n",
    "    The AI model does not understand anything, say, picture, text\n",
    "    Unless you transform it to integer and float tensors\n",
    "\n",
    "    Quantify and its subclass controls the\n",
    "        numericalization / collation of the data pipeline\n",
    "    The base class of quantify does: NOTHING\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, list_of_items):\n",
    "        return list(list_of_items)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        \"\"\"\n",
    "        A function to let the data processing\n",
    "        adapt to the data column\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __hash__(self,):\n",
    "        if hasattr(self, \"name\"):\n",
    "            return self.name\n",
    "        else:\n",
    "            return self.__class__.__name__\n",
    "\n",
    "\n",
    "class QuantifyImage(Quantify):\n",
    "    \"\"\"\n",
    "    Transform PIL.Image to tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mean_: LIST([\"imagenet\", \"0.5 x 3\"]) = \"imagenet\",\n",
    "        std_: LIST([\"imagenet\", \"0.5 x 3\"]) = \"imagenet\",\n",
    "    ):\n",
    "        if type(mean_) == str:\n",
    "            if mean_ == \"imagenet\":\n",
    "                mean_ = [0.485, 0.456, 0.406]\n",
    "            elif mean_ == \"0.5 x 3\":\n",
    "                mean_ = [.5, .5, .5]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Mean configuration: {mean_} not valid\")\n",
    "\n",
    "        if type(std_) == str:\n",
    "            if std_ == \"imagenet\":\n",
    "                std_ = [0.229, 0.224, 0.225]\n",
    "            elif std_ == \"0.5 x 3\":\n",
    "                std_ = [.5, .5, .5]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Standard Variation configuration: {std_} not valid\")\n",
    "\n",
    "        self.transform = tfm.Compose([\n",
    "            tfm.ToTensor(),\n",
    "            tfm.Normalize(mean=mean_, std=std_),\n",
    "        ])\n",
    "\n",
    "        self.shape = (BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Quantify Image to tensors:{self.transform}\"\n",
    "\n",
    "    def __call__(self, list_of_image):\n",
    "        return torch.stack(list(\n",
    "            self.transform(img) for img in list_of_image))\n",
    "\n",
    "\n",
    "class QuantifyText(Quantify):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained: STR(default=\"bert-base-cased\") = \"bert-base-cased\",\n",
    "        max_length: INT(default=512, min_=12, max_=1024, step=4) = 512,\n",
    "        padding: LIST(options=[\n",
    "            \"do_not_pad\",\n",
    "            \"max_length\",\n",
    "            \"longest\"], default=\"max_length\") = \"max_length\",\n",
    "        return_token_type_ids: BOOL(name=\"Token Type IDs\", default=True) = True,\n",
    "        return_attention_mask: BOOL(name=\"Attention Mask\", default=True) = True,\n",
    "        return_offsets_mapping: BOOL(name=\"Offset Mapping\", default=False) = False,\n",
    "    ):\n",
    "        self.pretrained = pretrained\n",
    "        self.max_length = max_length\n",
    "        self.padding = padding\n",
    "        self.return_token_type_ids = return_token_type_ids\n",
    "        self.return_attention_mask = return_attention_mask\n",
    "        self.return_offsets_mapping = return_offsets_mapping\n",
    "        self.truncation = True\n",
    "        self.return_tensors = 'pt'\n",
    "        self.shape = (BATCH_SIZE, SEQUENCE_SIZE)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        \"\"\"\n",
    "        Initialize tokenizer\n",
    "        \"\"\"\n",
    "        from transformers import AutoTokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.pretrained, use_fast=True)\n",
    "\n",
    "    def __call__(self, list_of_text: List[str]):\n",
    "        list_of_text = list(list_of_text)\n",
    "        return self.tokenizer(\n",
    "            list_of_text,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            truncation=self.truncation,\n",
    "            return_token_type_ids=self.return_token_type_ids,\n",
    "            return_attention_mask=self.return_attention_mask,\n",
    "            return_tensors=self.return_tensors,\n",
    "            return_offsets_mapping=self.return_offsets_mapping,\n",
    "        )\n",
    "\n",
    "\n",
    "class QuantifyCategory(Quantify):\n",
    "    \"\"\"\n",
    "    Transform single categorical data to index numbers in pytorch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_frequency: INT(min_=1, max_=20, default=1) = 1,\n",
    "    ):\n",
    "        self.min_frequency = min_frequency\n",
    "\n",
    "    def adapt(self, column):\n",
    "        # category statistics\n",
    "        value_counts = pd.DataFrame(column.value_counts())\n",
    "\n",
    "        # if minimun freq is 1\n",
    "        # very category occured should be accounted for\n",
    "        # hence no missing token padding is required\n",
    "        if self.min_frequency < 2:\n",
    "            self.category = Category(\n",
    "                arr=np.array(value_counts.index),\n",
    "                pad_mst=False)\n",
    "\n",
    "        # we need missing token\n",
    "        # for category's frequency < self.min_frequency\n",
    "        else:\n",
    "            categories = np.array(\n",
    "                list(value_counts.index[\n",
    "                    value_counts.values.reshape(-1) > self.min_frequency]))\n",
    "            self.category = Category(arr=categories, pad_mst=True)\n",
    "\n",
    "        self.shape = (BATCH_SIZE, len(self.category))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Quantify Category:{self.category}\"\n",
    "\n",
    "    def __call__(self, list_of_strings):\n",
    "        return torch.LongTensor(self.category.c2i[np.array(list_of_strings)])\n",
    "\n",
    "\n",
    "class QuantifyNum(Quantify):\n",
    "    \"\"\"\n",
    "    Quantify contineous data, like float numbers\n",
    "    The only process is normalization on the entire population\n",
    "    \"\"\"\n",
    "    shape = (BATCH_SIZE, 1)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        self.mean_ = column.mean()\n",
    "        self.std_ = column.std()\n",
    "\n",
    "    def __call__(self, list_of_num):\n",
    "        return (torch.FloatTensor(list_of_num)[None, :]-self.mean_)/self.std_\n",
    "\n",
    "    def backward(self, x):\n",
    "        return x*self.std_+self.mean_\n",
    "\n",
    "\n",
    "class QuantifyMultiCategory(Quantify):\n",
    "    \"\"\"\n",
    "    Turn Multi-categorical data to n_hot encoding numbers in pytorch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, col_name: str):\n",
    "        self.col_name = col_name\n",
    "\n",
    "\n",
    "QUANTIFY = dict(\n",
    "    Quantify=Quantify,\n",
    "    QuantifyNum=QuantifyNum,\n",
    "    QuantifyImage=QuantifyImage,\n",
    "    QuantifyCategory=QuantifyCategory,\n",
    "    QuantifyMultiCategory=QuantifyMultiCategory,\n",
    "    QuantifyText=QuantifyText,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A pytorch dataset working under our core engine\n",
    "    The dataset class should on be defined here once\n",
    "    \"\"\"\n",
    "    def __init__(self, df, columns: List[Any] = None):\n",
    "        self.df = df\n",
    "        self.columns = list(df.columns) if columns is None else columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        row = dict(self.df.loc[idx])\n",
    "        rt = dict()\n",
    "        for col in self.columns:\n",
    "            v = row[col]\n",
    "            if hasattr(v, \"is_enrich\"):\n",
    "                rt[col] = v.rowing(row)\n",
    "            else:\n",
    "                rt[col] = v\n",
    "        return rt\n",
    "    \n",
    "    def split(\n",
    "        self,\n",
    "        valid_ratio:FLOAT(min_=0.01, max_=0.5, default=.1, step=0.01)=.1\n",
    "    ) -> Tuple[Any]:\n",
    "        \"\"\"\n",
    "        Split dataset to train, validation\n",
    "        \"\"\"\n",
    "        cls = self.__class__\n",
    "        slicing = (np.random.rand(len(self)) < valid_ratio)\n",
    "        return (\n",
    "            cls(self.df[~slicing].reset_index(drop=True), self.columns),\n",
    "            cls(self.df[slicing].reset_index(drop=True), self.columns)\n",
    "        )\n",
    "\n",
    "    def dataloader(\n",
    "        self,\n",
    "        batch_size: LIST(options=[1, 2, 4, 8, 16, 32, 64, 128, 256, 512], default=32) = 32,\n",
    "        shuffle: LIST(options=[True, False], default=False) = False,\n",
    "        num_workers: LIST(options=[0, 2, 4, 8, 16], default=0) =0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create dataloader from dataset\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgebox.html import list_group_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rotten_tomatoes_link': 'm/0814255',\n",
       " 'critic_name': 'Nick Schager',\n",
       " 'top_critic': False,\n",
       " 'publisher_name': 'Slant Magazine',\n",
       " 'review_type': 'Rotten',\n",
       " 'review_score': 0.25,\n",
       " 'review_date': '2010-02-10',\n",
       " 'review_content': \"Harry Potter knockoffs don't come more transparent and slapdash than this wannabe-franchise jumpstarter directed by Chris Columbus.\"}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TaiChiDataset(base_df)\n",
    "ds[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose XY 🎸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_xy(df):\n",
    "    global phase\n",
    "    DOM(f\"{len(df)} rows of data, example table\", \"h3\")()\n",
    "    display(df.sample(5))\n",
    "    display(HTML(\"<hr>\"))\n",
    "    DOM(\"Please Choose Column\", \"h3\")()\n",
    "    DOM(\"The AI model will try to guess the Y with the input X\", \"div\", {\"style\":\"color:#666699\"})()\n",
    "    \n",
    "    task = 'quantify'\n",
    "    # enrich by columns\n",
    "    if \"enrich\" in phase:\n",
    "        by_destination = dict((en['dst'], en) for en in phase['enrich'])\n",
    "    else:\n",
    "        by_destination = dict()\n",
    "    \n",
    "    data_list = phase[task] if task in phase else []\n",
    "    mol_box = MoreOrLess(data_list)\n",
    "    display(mol_box)\n",
    "\n",
    "    @interact_manual\n",
    "    def set_quantify_(src=list(df.columns), use_for = [\"As X\", \"As Y\"]):\n",
    "        DOM(f\"Quantify Column: {src} {use_for}\", \"h4\")()\n",
    "        display(df[[src, ]].head(3))\n",
    "        \n",
    "        quantify_dropdown = Dropdown(options=list(QUANTIFY.keys()))\n",
    "        \n",
    "        # check the hint from last step\n",
    "        prefer = None\n",
    "        if src in by_destination:\n",
    "            col_config = by_destination[src]\n",
    "            cls = ENRICHMENTS[col_config['enrich']]\n",
    "\n",
    "            # In case the enrich layer has the preference\n",
    "            if hasattr(cls, \"prefer\"):\n",
    "                prefer = cls.prefer\n",
    "                \n",
    "                # set default value to drop down value,\n",
    "                # if the the previous hint suggest so\n",
    "                quantify_dropdown.value = prefer\n",
    "                DOM(f\"Prefered quantifying:\\t{cls.prefer}\", \"h4\")()\n",
    "            if hasattr(cls, \"typing\"):\n",
    "                DOM(f\"Output data type:\\t{cls.typing}\", \"h4\")()\n",
    "        \n",
    "        @interact_manual\n",
    "        def choose_quantify(quantify = quantify_dropdown):\n",
    "            cls = QUANTIFY[quantify]\n",
    "            def result_callback(kwargs):\n",
    "                extra = {\"src\": src, \"x\":(use_for==\"As X\"),\n",
    "                        \"kwargs\": kwargs, \"quantify\": cls.__name__}\n",
    "                mol_box+extra\n",
    "                phase['quantify'] = mol_box.get_data()\n",
    "                \n",
    "            obj, decoded = init_interact(cls, result_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>109468 rows of data, example table</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5092</th>\n",
       "      <td>m/10009462-g_force</td>\n",
       "      <td>Sean P. Means</td>\n",
       "      <td>False</td>\n",
       "      <td>Salt Lake Tribune</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2009-08-09</td>\n",
       "      <td>Guided by the principle that action movies hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101556</th>\n",
       "      <td>m/black_panther_2018</td>\n",
       "      <td>Nigel Andrews</td>\n",
       "      <td>True</td>\n",
       "      <td>Financial Times</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>Crashingly enjoyable, frequently exciting and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12576</th>\n",
       "      <td>m/1012225-les_miserables</td>\n",
       "      <td>Tim Brayton</td>\n",
       "      <td>False</td>\n",
       "      <td>Antagony &amp; Ecstasy</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>While there's no such thing as a timeless '30s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>m/10000_bc</td>\n",
       "      <td>Linda Cook</td>\n",
       "      <td>False</td>\n",
       "      <td>Quad City Times (Davenport, IA)</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2008-03-09</td>\n",
       "      <td>On a Neanderthal level, \"10,000 B.C.\" works.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>m/10007902-delirious</td>\n",
       "      <td>S. Jhoanna Robledo</td>\n",
       "      <td>False</td>\n",
       "      <td>Common Sense Media</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2007-10-22</td>\n",
       "      <td>Mature paparazzi drama isn't quite in focus.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rotten_tomatoes_link         critic_name  top_critic  \\\n",
       "5092          m/10009462-g_force       Sean P. Means       False   \n",
       "101556      m/black_panther_2018       Nigel Andrews        True   \n",
       "12576   m/1012225-les_miserables         Tim Brayton       False   \n",
       "284                   m/10000_bc          Linda Cook       False   \n",
       "1894        m/10007902-delirious  S. Jhoanna Robledo       False   \n",
       "\n",
       "                         publisher_name review_type  review_score review_date  \\\n",
       "5092                  Salt Lake Tribune      Rotten           0.5  2009-08-09   \n",
       "101556                  Financial Times       Fresh           0.8  2018-02-07   \n",
       "12576                Antagony & Ecstasy       Fresh           0.8  2013-01-06   \n",
       "284     Quad City Times (Davenport, IA)      Rotten           0.5  2008-03-09   \n",
       "1894                 Common Sense Media      Rotten           0.4  2007-10-22   \n",
       "\n",
       "                                           review_content  \n",
       "5092    Guided by the principle that action movies hav...  \n",
       "101556  Crashingly enjoyable, frequently exciting and ...  \n",
       "12576   While there's no such thing as a timeless '30s...  \n",
       "284          On a Neanderthal level, \"10,000 B.C.\" works.  \n",
       "1894         Mature paparazzi drama isn't quite in focus.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aaa0f5ba2cd44f5944ef9e17d44b5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<hr>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Please Choose Column</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"color:#666699\">The AI model will try to guess the Y with the input X</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00d2de79819413791a63ee9164d24a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MoreOrLess()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36534130d4742b0a47479fccd36b2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='src', options=('rotten_tomatoes_link', 'critic_name', 'top_critic'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "choose_xy(base_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check configuration after setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase:{\n",
       "  \"quantify\": [\n",
       "    {\n",
       "      \"src\": \"review_content\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"pretrained\": \"bert-base-cased\",\n",
       "        \"max_length\": 512,\n",
       "        \"padding\": \"max_length\",\n",
       "        \"return_token_type_ids\": true,\n",
       "        \"return_attention_mask\": true,\n",
       "        \"return_offsets_mapping\": false\n",
       "      },\n",
       "      \"quantify\": \"QuantifyText\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"rotten_tomatoes_link\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"min_frequency\": 1\n",
       "      },\n",
       "      \"quantify\": \"QuantifyCategory\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"review_score\",\n",
       "      \"x\": false,\n",
       "      \"kwargs\": {},\n",
       "      \"quantify\": \"QuantifyNum\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_quantify(\n",
    "    df: pd.DataFrame, phase:Phase\n",
    "):\n",
    "    # existance check\n",
    "    if 'quantify' not in phase:\n",
    "        raise KeyError(f\"No quantify stepset\")\n",
    "    \n",
    "    qdict = dict()\n",
    "    for i, qconf in tqdm(enumerate(phase['quantify']), leave = False):\n",
    "        qname = qconf['quantify']\n",
    "        kwargs = qconf['kwargs']\n",
    "        src = qconf['src']\n",
    "        x = qconf['x']\n",
    "        \n",
    "        cls = QUANTIFY[qname]\n",
    "        qobj = cls(**kwargs)\n",
    "        qobj.src = src\n",
    "        qobj.is_x = x\n",
    "        qobj.adapt(df[src])\n",
    "        qdict.update({src:qobj})\n",
    "    return qdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qdict = execute_quantify(base_df, phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_content': <__main__.QuantifyText at 0x7f936baaed50>,\n",
       " 'rotten_tomatoes_link': Quantify Category:Category Manager with 3869,\n",
       " 'review_score': <__main__.QuantifyNum at 0x7f92b898fa10>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiCollate:\n",
    "    \"\"\"\n",
    "    Universal all power full collate function\n",
    "    1 for all collation\n",
    "    \"\"\"\n",
    "    def __init__(self, quantify_dict):\n",
    "        self.quantify_dict = quantify_dict\n",
    "        \n",
    "    def make_df(self, batch):\n",
    "        return pd.DataFrame(list(batch))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.quantify_dict)\n",
    "        \n",
    "    def __call__(self, batch) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        This call will execute the __call__(a_list_of_items)\n",
    "        from Quantify objects column by column\n",
    "        \"\"\"\n",
    "        batch_df = self.make_df(batch)\n",
    "        rt = dict()\n",
    "        for src,qobj in self.quantify_dict.items():\n",
    "            rt.update({\n",
    "                src:qobj(list(batch_df[src]))\n",
    "            })\n",
    "        return rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part handles:\n",
    "* Spliting\n",
    "* To dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset: TaiChiDataset, quantify_dict: Dict[str, Quantify]):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.quantify_dict = quantify_dict\n",
    "        \n",
    "        self.collate = TaiChiCollate(quantify_dict)\n",
    "        \n",
    "    def configure(\n",
    "        self,\n",
    "        valid_ratio:FLOAT(min_=0.01, max_=0.5, default=.1, step=0.01)=.1,\n",
    "        batch_size: LIST(options=[1, 2, 4, 8, 16, 32, 64, 128, 256, 512], default=32) = 32,\n",
    "        shuffle: LIST(options=[True, False], default=False) = True,\n",
    "        num_workers: LIST(options=[0, 2, 4, 8, 16], default=0) =0,\n",
    "    ):  \n",
    "        self.train_ds, self.val_ds = self.dataset.split(valid_ratio)\n",
    "        self.batch_size=batch_size\n",
    "        self.shuffle=shuffle\n",
    "        self.num_workers=num_workers\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        self.train_dl = self.train_ds.dataloader(\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers)\n",
    "        self.train_dl.collate_fn = self.collate\n",
    "        return self.train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        self.val_dl = self.val_ds.dataloader(\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers)\n",
    "        self.val_dl.collate_fn = self.collate\n",
    "        return self.val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_datamodule(df, qdict, phase):\n",
    "    ds = TaiChiDataset(df)\n",
    "    datamodule = TaiChiDataModule(ds, qdict)\n",
    "    \n",
    "    def configure_setting(kwargs):\n",
    "        global phase\n",
    "        datamodule.configure(**kwargs)\n",
    "        phase['batch_level'] = kwargs\n",
    "    interact_intercept(datamodule.configure, configure_setting)\n",
    "    return datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b637d80c4740608c3bf2d890b62da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='valid_ratio', max=0.5, min=0.01, step=0.01), Dropdow…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datamodule = execute_datamodule(base_df, qdict, phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(datamodule.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase:{\n",
       "  \"quantify\": [\n",
       "    {\n",
       "      \"src\": \"review_content\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"pretrained\": \"bert-base-cased\",\n",
       "        \"max_length\": 512,\n",
       "        \"padding\": \"max_length\",\n",
       "        \"return_token_type_ids\": true,\n",
       "        \"return_attention_mask\": true,\n",
       "        \"return_offsets_mapping\": false\n",
       "      },\n",
       "      \"quantify\": \"QuantifyText\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"rotten_tomatoes_link\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"min_frequency\": 1\n",
       "      },\n",
       "      \"quantify\": \"QuantifyCategory\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"review_score\",\n",
       "      \"x\": false,\n",
       "      \"kwargs\": {},\n",
       "      \"quantify\": \"QuantifyNum\"\n",
       "    }\n",
       "  ],\n",
       "  \"batch_level\": {\n",
       "    \"valid_ratio\": 0.1,\n",
       "    \"batch_size\": 16,\n",
       "    \"shuffle\": true,\n",
       "    \"num_workers\": 0\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_content': {'input_ids': tensor([[  101,   138,  9189,  ...,     0,     0,     0],\n",
       "         [  101,  1247,   112,  ...,     0,     0,     0],\n",
       "         [  101, 15295,  1105,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,   119,   119,  ...,     0,     0,     0],\n",
       "         [  101,  9326, 12788,  ...,     0,     0,     0],\n",
       "         [  101,  1109,  1842,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])},\n",
       " 'rotten_tomatoes_link': tensor([ 109,  475,  154,  495, 1958,  372,  967,  341,  399, 1430,  704, 1396,\n",
       "           78, 1023,  219, 1923]),\n",
       " 'review_score': tensor([[ 0.3153, -0.9577, -1.9910,  0.3153, -1.0684,  1.1225, -1.7603,  0.7766,\n",
       "          -0.1459,  0.7766,  1.6991, -0.1459, -1.0684,  0.3153, -0.6072, -0.1459]])}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Choose your model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import (\n",
    "    resnet18, resnet34, resnet50, resnet101, resnet152,\n",
    "    resnext101_32x8d, resnext50_32x4d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESNET_OPTIONS = {\"resnet18\": resnet18,\n",
    "                  \"resnet34\": resnet34,\n",
    "                  \"resnet50\": resnet50,\n",
    "                  \"resnet101\": resnet101,\n",
    "                  \"resnet152\": resnet152,\n",
    "                  \"resnext101_32x8d\": resnext101_32x8d,\n",
    "                  \"resnext50_32x4d\": resnext50_32x4d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidJoint1d(nn.Module):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "    \n",
    "    def forward(self, data):\n",
    "        tensors = list(data[key] for key in self.keys)\n",
    "        return torch.cat(tensors,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntryModel(nn.Module):\n",
    "    is_entry = True\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, ):\n",
    "        raise ImportError(\n",
    "            f\"Please define class function 'from_quantify' for {cls.__name__}\"\n",
    "        )\n",
    "    \n",
    "class Empty(EntryModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.out_features=1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls,\n",
    "        quantify):\n",
    "        return cls()\n",
    "\n",
    "class ImageConvEncoder(EntryModel):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.name = \"cnn\"\n",
    "        self.output_shape = (BATCH_SIZE, model.fc.in_features)\n",
    "        self.out_features = model.fc.in_features\n",
    "        model.fc = Empty()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"\"\"ComputerVisionEncoder: {self.name}\n",
    "        Outputs shape:{self.output_shape}\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        name: LIST(options=list(\n",
    "            RESNET_OPTIONS.keys()), default=\"resnet18\"),\n",
    "    ):\n",
    "        model = RESNET_OPTIONS[name](pretrained=True, progress=True,)\n",
    "        obj = cls(model)\n",
    "        obj.name = name\n",
    "        return obj\n",
    "\n",
    "\n",
    "class CategoryEncoder(EntryModel):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Embedding(\n",
    "            num_embeddings,\n",
    "            embedding_dim)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        return self.model(idx)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        embedding_dim: LIST(\n",
    "            options=[4, 8, 16, 32, 64, 128, 256, 512], default=128) = 128):\n",
    "        num_embeddings = len(quantify.category)\n",
    "        obj = CategoryEncoder(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "        obj.out_features = embedding_dim\n",
    "        return obj\n",
    "\n",
    "\n",
    "class TransformerEncoder(EntryModel):\n",
    "    \"\"\"\n",
    "    A model part to encode sequnce data in to vectors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, encoder_mode: BOOL(default=True) = True,):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.encoder_mode = encoder_mode\n",
    "\n",
    "    def forward(self, kwargs):\n",
    "        outputs = self.model(**kwargs)\n",
    "        if self.encoder_mode:\n",
    "            # output vector\n",
    "            if \"pooler_output\" in outputs:\n",
    "                return outputs.pooler_output\n",
    "            else:\n",
    "                return (\n",
    "                    outputs.last_hidden_state*kwargs['attention_mask'][:,:,None]\n",
    "                ).mean(1)\n",
    "        return outputs\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        name: STR(default=\"bert-base-uncased\") = 'bert-base-uncased',\n",
    "        encoder_mode: BOOL(default=True) = True,\n",
    "    ):\n",
    "        from transformers import AutoModel\n",
    "        model = AutoModel.from_pretrained(name)\n",
    "        obj = cls(model)\n",
    "        obj.name = name\n",
    "        obj.encoder_mode = encoder_mode\n",
    "        if encoder_mode:\n",
    "            obj.out_features= model.config.hidden_size\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "entry = TransformerEncoder.from_quantify(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    vector = entry(data['review_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 768])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry = ImageConvEncoder.from_quantify(0,name=\"resnet18\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     vectors = entry(data['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exit modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_, y):\n",
    "    return (y_.argmax(-1) == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExitModel(nn.Module):\n",
    "    metric_funcs = dict()\n",
    "\n",
    "    def loss_step(self, x, y):\n",
    "        y_ = self(x)\n",
    "        loss = self.crit(y_, y)\n",
    "        metrics = dict()\n",
    "        for k, func in self.metric_funcs.items():\n",
    "            metrics.update({k:func(y_, y)})\n",
    "        return dict(loss=loss, y_=y_, **metrics)\n",
    "    \n",
    "class CategoryTop(ExitModel):\n",
    "    prefer = \"CrossEntropyLoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.activation = nn.Softmax(dim=-1)\n",
    "        self.crit = nn.CrossEntropyLoss()\n",
    "        self.metric_funcs.update({\"acc\":accuracy})\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = len(quantify.category)\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )\n",
    "\n",
    "class MultiCategoryTop(ExitModel):\n",
    "    prefer = \"BCEWithLogitsLoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "    \n",
    "    def loss_step(self, x, y):\n",
    "        y_ = self(x)\n",
    "        loss = self.crit(y_, y)\n",
    "        return {\"loss\": loss, \"y_\": self.activation(y_)}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = len(quantify.category)\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )\n",
    "\n",
    "\n",
    "class RegressionTop(ExitModel):\n",
    "    prefer = \"MSELoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.crit = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = 1\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EntireModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping quantify to the following entry or exit model\n",
    "QUANTIFY_2_ENTRY_MAP = dict({\n",
    "    QuantifyImage:[\n",
    "        ImageConvEncoder,\n",
    "    ],\n",
    "    QuantifyCategory:[\n",
    "        CategoryEncoder,\n",
    "    ],\n",
    "    QuantifyText:[\n",
    "        TransformerEncoder,\n",
    "    ],\n",
    "    QuantifyNum:[\n",
    "        Empty,\n",
    "    ],\n",
    "})\n",
    "QUANTIFY_2_EXIT_MAP = dict({\n",
    "    QuantifyCategory:[\n",
    "        CategoryTop,\n",
    "    ],\n",
    "    QuantifyNum:[\n",
    "        RegressionTop,\n",
    "    ],\n",
    "})\n",
    "\n",
    "# all entry and exit model\n",
    "ENTRY_ALL = dict(\n",
    "    ImageConvEncoder=ImageConvEncoder,\n",
    "    CategoryEncoder=CategoryEncoder,\n",
    "    TransformerEncoder=TransformerEncoder,\n",
    "    Empty=Empty,\n",
    ")\n",
    "EXIT_ALL = dict(\n",
    "    CategoryTop=CategoryTop,\n",
    "    RegressionTop=RegressionTop,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_models(quantify, cls_options, model_conf:str='x_models'):\n",
    "    def config_model(ModelClass=cls_options):\n",
    "        def starting_cls(kwargs):\n",
    "            global phase\n",
    "            if model_conf in phase:\n",
    "                models = phase[model_conf]\n",
    "            else:\n",
    "                models = dict()\n",
    "            models[quantify.src] = dict(\n",
    "            model_name=ModelClass.__name__,\n",
    "            src=quantify.src,\n",
    "            kwargs=kwargs,\n",
    "            )\n",
    "            phase[model_conf] = models\n",
    "        ia = InteractiveAnnotations(\n",
    "            ModelClass.from_quantify,\n",
    "            description=\"Okay\",\n",
    "            icon='rocket',\n",
    "            button_style='success')\n",
    "            \n",
    "        ia.register_callback(starting_cls)\n",
    "        display(ia.vbox)\n",
    "    inter = interact_manual(config_model)\n",
    "    reconfig_manual_interact(\n",
    "        inter.widget,\n",
    "        description=\"Yes!\", icon=\"cube\", button_style='info')\n",
    "    return inter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model(quantify_dict: Dict[str, Quantify]):\n",
    "    global phase\n",
    "    x_models = dict()\n",
    "    y_models = dict()\n",
    "    for src, quantify in quantify_dict.items():\n",
    "        if quantify.is_x:\n",
    "            entry_cls_options = dict(\n",
    "                (q.__name__, q)\n",
    "                for q in QUANTIFY_2_ENTRY_MAP.get(quantify.__class__))\n",
    "\n",
    "            if entry_cls_options is None:\n",
    "                print(f\"We do not support {quantify.__class__} as X data\")\n",
    "                continue\n",
    "            display(HTML(f\"\"\"\n",
    "            <h3 class='text-primary'>Choose Model For X Column:\n",
    "            <strong>{src}</strong></h3>\"\"\"))\n",
    "            choose_models(quantify, entry_cls_options, \"x_models\")\n",
    "    for src, quantify in quantify_dict.items():\n",
    "        if quantify.is_x == False:\n",
    "            exit_cls_options = dict(\n",
    "                (q.__name__, q)\n",
    "                for q in QUANTIFY_2_EXIT_MAP.get(quantify.__class__))\n",
    "            if entry_cls_options is None:\n",
    "                print(f\"We do not support {quantify.__class__} as Y data\")\n",
    "            display(HTML(f\"\"\"\n",
    "            <h3 class='text-danger'>Choose Model For Y Column:\n",
    "            <strong>{src}</strong></h3>\"\"\"))\n",
    "            choose_models(quantify, exit_cls_options, \"y_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e18072a5e0467e9ee935959e8b306a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n            <h3 class='text-primary'>Choose Model For X Column:\\n            <strong>review_cont…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ff17c757cc4cc3a8c0231966f233e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ModelClass', options={'TransformerEncoder': <class '__main__.Trans…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e427b42e5519402f9ad96754923823fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n            <h3 class='text-primary'>Choose Model For X Column:\\n            <strong>rotten_toma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bff6916bae34535805e92fc9f3d5e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ModelClass', options={'CategoryEncoder': <class '__main__.Category…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55519f5c3214455b2ed208105a1c4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n            <h3 class='text-danger'>Choose Model For Y Column:\\n            <strong>review_score…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8f64af837d4b818a25509b657f398b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ModelClass', options={'RegressionTop': <class '__main__.Regression…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_model(qdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase:{\n",
       "  \"quantify\": [\n",
       "    {\n",
       "      \"src\": \"review_content\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"pretrained\": \"bert-base-cased\",\n",
       "        \"max_length\": 512,\n",
       "        \"padding\": \"max_length\",\n",
       "        \"return_token_type_ids\": true,\n",
       "        \"return_attention_mask\": true,\n",
       "        \"return_offsets_mapping\": false\n",
       "      },\n",
       "      \"quantify\": \"QuantifyText\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"rotten_tomatoes_link\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"min_frequency\": 1\n",
       "      },\n",
       "      \"quantify\": \"QuantifyCategory\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"review_score\",\n",
       "      \"x\": false,\n",
       "      \"kwargs\": {},\n",
       "      \"quantify\": \"QuantifyNum\"\n",
       "    }\n",
       "  ],\n",
       "  \"batch_level\": {\n",
       "    \"valid_ratio\": 0.1,\n",
       "    \"batch_size\": 16,\n",
       "    \"shuffle\": true,\n",
       "    \"num_workers\": 0\n",
       "  },\n",
       "  \"x_models\": {\n",
       "    \"rotten_tomatoes_link\": {\n",
       "      \"model_name\": \"CategoryEncoder\",\n",
       "      \"src\": \"rotten_tomatoes_link\",\n",
       "      \"kwargs\": {\n",
       "        \"embedding_dim\": 64\n",
       "      }\n",
       "    },\n",
       "    \"review_content\": {\n",
       "      \"model_name\": \"TransformerEncoder\",\n",
       "      \"src\": \"review_content\",\n",
       "      \"kwargs\": {\n",
       "        \"name\": \"bert-base-uncased\",\n",
       "        \"encoder_mode\": true\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"y_models\": {\n",
       "    \"review_score\": {\n",
       "      \"model_name\": \"RegressionTop\",\n",
       "      \"src\": \"review_score\",\n",
       "      \"kwargs\": {}\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntryDict(nn.Module):\n",
    "    \"\"\"\n",
    "    Create entry parts for different columns\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        phase: Phase,\n",
    "        qdict: Dict[str, EntryModel]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        model_dict = nn.ModuleDict()\n",
    "        for src, model_cfg in phase['x_models'].items():\n",
    "            quantify = qdict[src]\n",
    "            \n",
    "            # find column class\n",
    "            model_cls = ENTRY_ALL[model_cfg['model_name']]\n",
    "            # the kwargs to start the column model object\n",
    "            model_kwargs = model_cfg['kwargs']\n",
    "            # the model object\n",
    "            model = model_cls.from_quantify(quantify, **model_kwargs)\n",
    "            \n",
    "            # add the model by column name\n",
    "            model_dict[src] = model\n",
    "        \n",
    "        # calculate the output size for dimention 1 (after concatenation)\n",
    "        self.out_features = sum(\n",
    "            list(model.out_features for src, model in model_dict.items()))\n",
    "        self.model_dict = model_dict\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = []\n",
    "        for src, model in self.model_dict.items():\n",
    "            # input data for column\n",
    "            src_input = inputs[src]\n",
    "            \n",
    "            # forward pass for column_model(column_data)\n",
    "            outputs.append(model(src_input))\n",
    "        # concat the results\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "entry_dict = EntryDict(phase, qdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_ = entry_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 832])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssembledModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        phase: Phase,\n",
    "        qdict: Dict[str, EntryModel],\n",
    "        entry_lr: LIST(options=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6], default=1e-4)=1e-4,\n",
    "        exit_lr: LIST(options=[1e-1, 1e-2, 1e-3, 1e-4, ], default=1e-3)=1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.entry_lr = entry_lr\n",
    "        self.exit_lr = exit_lr\n",
    "        self.entry_dict = EntryDict(phase, qdict)\n",
    "        exit_cfg = list(phase['y_models'].values())[0]\n",
    "        \n",
    "        self.exit_src = exit_cfg['src']\n",
    "        self.exit_kwargs = exit_cfg['kwargs']\n",
    "        exit_cls = EXIT_ALL[exit_cfg['model_name']]\n",
    "        \n",
    "        exit_quantify = qdict[self.exit_src]\n",
    "        \n",
    "        self.exit_part = exit_cls.from_quantify(\n",
    "            exit_quantify,self.entry_dict, **self.exit_kwargs)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        vec = self.entry_dict(inputs)\n",
    "        return self.exit_part(vec)\n",
    "    \n",
    "    def loss_step(self, inputs):\n",
    "        vec = self.entry_dict(inputs)\n",
    "        return self.exit_part.loss_step(vec, inputs[self.exit_src])\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        rt = self.loss_step(batch)\n",
    "        for k, v in rt.items():\n",
    "            if v.numel()==1:\n",
    "                self.log(f\"trn_{k}\", v)\n",
    "        return rt['loss']\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        rt = self.loss_step(batch)\n",
    "        for k, v in rt.items():\n",
    "            if v.numel()==1:\n",
    "                self.log(f\"val_{k}\", v)\n",
    "        return rt['loss']\n",
    "    \n",
    "    def configure_optimizers(self,):\n",
    "        param_groups = [\n",
    "            {\"params\":self.entry_dict.parameters(), \"lr\":self.entry_lr},\n",
    "            {\"params\":self.exit_part.parameters(), \"lr\":self.exit_lr},\n",
    "        ]\n",
    "        return torch.optim.Adam(param_groups)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(phase, qdict):\n",
    "    if \"y_models\" in phase:\n",
    "        y_models = phase[\"y_models\"]\n",
    "        if len(y_models)>1:\n",
    "            raise ValueError(\"Multiple targets are not supported by now\")\n",
    "        else:\n",
    "            return AssembledModel(phase, qdict)\n",
    "    else:\n",
    "        raise ValueError(\"phase must contain 'y_models' configuration for now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "final_model = create_model(phase, qdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([1, 16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    final_model.loss_step(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_slug_name(phase):\n",
    "    xs = '-'.join(list(q['src'] for q in phase['quantify'] if q[\"x\"]))\n",
    "    ys = '-'.join(list(q['src'] for q in phase['quantify'] if q[\"x\"]==False))\n",
    "    return '_'.join([xs,'to',ys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vivid **name** for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'review_content-rotten_tomatoes_link_to_review_score'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASK_SLUG = make_slug_name(phase)\n",
    "TASK_SLUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgebox.thunder.callbacks import DataFrameMetricsCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainer(\n",
    "    project:STR(default=\"default\",) = \"default\",\n",
    "    tensorboard: BOOL(default=True)=True,\n",
    "    show_metric: BOOL(default=True)=True,\n",
    "    max_epochs: INT(min_=1, max_=200, default=5)=5,\n",
    "    use_gpu:BOOL(default=True)=True,\n",
    "):\n",
    "    global phase\n",
    "    if project=='default':\n",
    "        global PROJECT\n",
    "        if str(PROJECT)!=\"None\":\n",
    "            project = PROJECT\n",
    "        else:\n",
    "            project = \"./project\"\n",
    "    project = Path(project)\n",
    "    TASK_SLUG = make_slug_name(phase)\n",
    "    csv_logger = pl.loggers.CSVLogger(project/\"csv_log\", name = TASK_SLUG, )\n",
    "    loggers = [\n",
    "        csv_logger\n",
    "    ]\n",
    "    if tensorboard:\n",
    "        loggers.append(\n",
    "            pl.loggers.TensorBoardLogger(save_dir=project/'tensorboard', name=TASK_SLUG)\n",
    "        )\n",
    "    rt = dict(\n",
    "        max_epochs = max_epochs,\n",
    "        logger =loggers)\n",
    "    callbacks = []\n",
    "    if show_metric:\n",
    "        callbacks.append(\n",
    "            DataFrameMetricsCallback())\n",
    "        \n",
    "    rt.update({\"callbacks\":callbacks})\n",
    "    \n",
    "    if use_gpu:\n",
    "        rt.update(dict(gpus=1))\n",
    "#     rt.update(dict(\n",
    "#         auto_select_gpus=True,\n",
    "#     ))\n",
    "    return rt\n",
    "\n",
    "def run_training(final_model, datamodule):\n",
    "    def set_trainer_callback(kwargs):\n",
    "        trainer_kwargs = set_trainer(**kwargs)\n",
    "        trainer = pl.Trainer(**trainer_kwargs)\n",
    "        trainer.fit(final_model, datamodule=datamodule)\n",
    "        return trainer\n",
    "    return set_trainer_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a68d32e8254c5a879daf54f150a6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='default', description='project'), Checkbox(value=True, description='tensorbo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({}, <function __main__.interact_intercept.<locals>.fillin_init(**kwargs)>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d093cbb83760430b82dd8e39a885bdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type          | Params\n",
      "---------------------------------------------\n",
      "0 | entry_dict | EntryDict     | 109 M \n",
      "1 | exit_part  | RegressionTop | 833   \n",
      "---------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "438.923   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:349: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  f'Your {mode}_dataloader has `shuffle=True`, it is best practice to turn'\n",
      "/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n",
      "/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([1, 16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ec5174078a4bbe8dd157df09495e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([1, 16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:897: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n"
     ]
    }
   ],
   "source": [
    "interact_intercept(set_trainer, run_training(final_model, datamodule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242.073px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
