# -*- coding: utf-8 -*-
# ----------------------------------------------
# purpose: å¹¿å‘Šåƒåœ¾æ£€æµ‹
# author : 
# create_time : 2020/6/29 15:32
# update_time : 2020/6/29 15:32
# copyright : Lavector
# ----------------------------------------------
"""
å¹¿å‘Šæ¸…æ´—
"""
import re
import codecs
import numpy as np

from maxda.util.mysql_util import *
from maxda.analysis.da_clean.clean_interface import *


class SpamInterface(object):
    def predict(self, text, params=None):
        """
        :param text:
        :param params:
        :return: bool
        """
        pass


class OrdinaryWays(object):
    @staticmethod
    def get_from2mysql(c_type="adword"):
        sql = """
        select keyword from %s
        """ % c_type
        result = np.array(LavwikiReader.execute_all(sql)[0])
        result = [i[0] for i in result]
        return result

    @staticmethod
    def get_clean(c_type):
        """
        type:mysqlæ•°æ®åº“è¡¨åï¼Œå¤„ç†weiboåƒåœ¾ã€æ°´å†›æ—¶çš„è¯

        """
        clean = OrdinaryWays.get_from2mysql(c_type)
        clean = [str(i).lower().strip() for i in clean if len(str(i).strip()) > 0]
        return clean

    @staticmethod
    def read_by_line(file_path):
        """
        æŒ‰è¡Œè¯»å–æ•°æ®
        :param file_path:
        :return:
        """
        data_list = list()
        with codecs.open(file_path, 'r', encoding="utf-8") as fp:
            for line in fp:
                line = line.strip()
                if len(line) > 0:
                    data_list.append(line)

        return data_list

    @staticmethod
    def has_chinese_count(text):
        """
        åˆ¤æ–­ä¸­æ–‡å­—ç¬¦æ•°é‡
        :param self:
        :param text:
        :return:
        """
        count = 0
        tmp_text = text
        if isinstance(tmp_text, str):
            tmp_text = str(tmp_text)
        for ch in tmp_text:
            if '\u4e00' <= ch <= '\u9fff':
                count += 1
        return count

    @staticmethod
    def is_num(text):
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºæ•°å­—ï¼ŒåŒ…æ‹¬æ•´æ•°å’Œæµ®ç‚¹æ•°
        :param text:
        :return:
        """
        # return text.isdigit()

        # pattern = re.compile(r'^[-+]?[-0-9]\d*\.\d*|[-+]?\.?[0-9]\d*$')
        # result = pattern.match(text)
        # if result:
        #     return True
        # else:
        #     return False

        if text.replace('.', '', 1).isdigit():
            return True
        return False

    @staticmethod
    def get_spam_dict(dict_file_path):
        word_set = set()
        # 1.åŠ è½½å¹¿å‘Šè¯
        word_list = OrdinaryWays.read_by_line(dict_file_path)
        for word in word_list:
            tmp_word = word.strip()
            if tmp_word:
                # TODO å…¨éƒ¨è½¬å°å†™
                word_set.add(tmp_word.lower())

        return word_set


class SpamPatternRule(SpamInterface):
    """
    åŸºäºæ­£åˆ™è§„åˆ™åˆ¤æ–­ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šçš„æ­£åˆ™è¡¨è¾¾å¼
    """
    def __init__(self):
        self.ads_item_rule_list = list()
        self._load()

    def _load(self):
        tmp_rule_set = OrdinaryWays.get_clean('weibo_ads_pattern_rule')
        for tmp_rule in tmp_rule_set:
            tmp_rule_pattern = re.compile(tmp_rule, re.S)
            self.ads_item_rule_list.append(tmp_rule_pattern)

    def predict(self, text, params=None):
        for re_rule_pattern in self.ads_item_rule_list:
            result = re_rule_pattern.search(text)
            if result and result.group() is not None:
                return True
        return False


class SpamHastagRule(SpamInterface):
    """
    åŸºäº Hasttag ä¸­çš„å†…å®¹è¿›è¡Œåˆ¤æ–­
    å¤„ç†ç±»å‹åŒpattern rule
    """

    def __init__(self, other_rule_list=None):
        """
        :param dict_file_path:
        :param other_rule_list: å…¶ä»–è‡ªå®šä¹‰çš„è§„åˆ™
        """
        self.item_rule_list = list()
        self.other_rule_list = other_rule_list

        self._load()

    def _load(self):
        tmp_rule_set = OrdinaryWays.get_clean('weibo_ads_hastag_rule')

        for tmp_rule in tmp_rule_set:
            tmp_rule_pattern = re.compile(tmp_rule, re.S)
            self.item_rule_list.append(tmp_rule_pattern)

    def is_match(self, text, params=None):
        for re_rule_pattern in self.item_rule_list:
            result = re_rule_pattern.search(text)
            if result and result.group() is not None:
                return True
        return False

    def predict(self, text, params=None):
        r2_list = self._get_bracket(text, (u'ã€', u'ã€‘'))
        bracket_list = r2_list

        for item in bracket_list:
            tmp_item = item.strip()
            if self.other_rule_list:
                for other_rule in self.other_rule_list:
                    if other_rule.predict(tmp_item):
                        return True

            if self.is_match(tmp_item):
                return True
        return False

    def _get_bracket(self, text, bracket, drop_bracket=True):
        tmp_text = text
        re_string = u"[{}].*?[{}]".format(bracket[0], bracket[1])
        p1 = re.compile(re_string, re.S)  # æœ€å°åŒ¹é…
        find_list = re.findall(p1, tmp_text)

        result_list = list()
        if find_list:
            for item in find_list:
                tmp_item = item
                if drop_bracket:
                    tmp_item = tmp_item.replace(bracket[0], u'')
                    tmp_item = tmp_item.replace(bracket[1], u'')
                # TODO,ç”±äºæŠ“å–æ•°æ®è§£æé—®é¢˜ï¼Œå¯èƒ½è®¸å¤šç¬¦å·ä¼šæ˜¾ç¤ºä¸ºï¼Ÿå·ï¼Œå› æ­¤å…¨æ›¿æ¢æ‰
                tmp_item = tmp_item.replace(u'?', u'')
                result_list.append(tmp_item)
        return result_list


class ItemPriceRule(SpamInterface):
    """
    åˆ¤æ–­æ˜¯å¦è¡¨ç¤ºä»·æ ¼
    """
    def __init__(self):
        price_rule_str_list = [u'(ï¿¥|\$)\d+(\.\d+)?',
                               u'\d+(\.\d+)?(å…ƒ|å…¥)']
        rule_str = u'|'.join(price_rule_str_list)
        rule_str = u'(' + rule_str + u')'

        self.price_rule_pattern = re.compile(rule_str, re.S)

    def predict(self, text, params=None):
        """
        åˆ¤æ–­æ˜¯å¦è¡¨ç¤ºä»·æ ¼,åªæ˜¯è¡¨ç¤ºå¯èƒ½æ˜¯ä»·æ ¼
        :param text:
        :return:
        """
        tmp_text = text
        # 1.æ ¹æ®æ­£åˆ™æŸ¥æ‰¾
        tmp_text = tmp_text.replace(u' ', u'')

        result = self.price_rule_pattern.search(tmp_text)
        if result and result.group() is not None:
            return True

        # 2.æ˜¯å¦ä¸ºã€ã€‘åŒ…èµ·æ¥çš„æ•°å­—
        if u'ã€' in tmp_text or u'ã€‘' in tmp_text:
            tmp_item = tmp_text.replace(u'ã€', u'')
            tmp_item = tmp_item.replace(u'ã€‘', u'')
            if OrdinaryWays.is_num(tmp_item):
                return True

        return False

class ItemNumRule(SpamInterface):
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºæ•°å­—
    """
    def predict(self, text, params=None):
        if OrdinaryWays.is_num(text):
            return True

        return False


class SpamWordRule(SpamInterface):
    """
    æ ¹æ®æ˜¯å¦åŒ…å«ç‰¹å®šçš„è¯æ¥åˆ¤æ–­
    """

    def __init__(self,use_re=False):
        """

        :param dict_file_path:
        :param use_re: æ˜¯å¦ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
        """
        self.word_set = set()
        self.rule_pattern = None

        self._load()

        self.use_re = use_re

    def _load(self):
        self.word_set = OrdinaryWays.get_clean('weibo_ads_word')
        self.rule_pattern = re.compile(u'|'.join(self.word_set), re.S)

    def _do_by_re(self, text, params=None):
        result = self.rule_pattern.search(text)
        if result and result.group() is not None:
            return True

        return False

    def _do(self, text, params=None):
        for word in self.word_set:
            if word in text:
                return True

        return False

    def predict(self, text, params=None):
        if self.use_re:
            return self._do_by_re(text)
        return self._do(text)


class AdsDelimiter(SpamInterface):
    """
    æŒ‰ç…§åˆ†éš”ç¬¦ï¼Œæ¥åˆ¤æ–­æ˜¯å¦ä¸ºå¹¿å‘Š
    """
    # æ³¨æ„ æœ€åä¸€ä¸ªæ˜¯ç©ºæ ¼ç¬¦
    SPLIT_CHAR = u'ï¼Œ '
    MAX_WORD_LEN = 30

    def __init__(self, rule_price):
        self.rule_price = rule_price

        self.item_rule_list = list()

        rule_str_set = OrdinaryWays.get_clean("weibo_ads_delimiter_rule")
        for tmp_rule in rule_str_set:
            tmp_rule_pattern = re.compile(tmp_rule, re.S)
            self.item_rule_list.append(tmp_rule_pattern)

    def match_by_pattern(self, text, params=None):
        """
        æ ¹æ®æ­£åˆ™åŒ¹é…æŸ¥æ‰¾
        :param text:
        :param params:
        :return:
        """
        for re_rule_pattern in self.item_rule_list:
            result = re_rule_pattern.search(text)
            if result and result.group() is not None:
                return True
        return False

    def predict(self, text, params=None):
        chinese_char_count = OrdinaryWays.has_chinese_count(text)
        if chinese_char_count > self.MAX_WORD_LEN:
            return False

        # æ‹†åˆ†æ•°æ®ï¼Œè¿›è¡Œå¤„ç†
        re_string = u'[{}]'.format(self.SPLIT_CHAR)
        text_list = re.split(re_string, text)
        text_list = [item.strip() for item in text_list if item.strip()]

        if len(text_list) < 2:
            return False

        # æ ¹æ®å¹¿å‘Šè¯åˆ¤æ–­
        if self.match_by_pattern(text):
            return True

        # æ ¹æ®æ˜¯å¦æœ‰ä»·æ ¼æ ‡è¯†
        for item in text_list:
            # å‡ ä¹ä¸€å®šæ˜¯ä»·æ ¼
            if self.rule_price.predict(item) and len(item) < 6:
                return True
            # æ˜¯æ•°å­—ï¼Œä½†å¯èƒ½æ˜¯ä»·æ ¼
            if OrdinaryWays.is_num(item.strip()) and len(text_list) < 6:
                return True
            # è‹±æ–‡ off,eg:Burberry vip 50% off åªæœ‰355/36 ?
            if u'off' in item:
                return True

        return False


class AdsLineRule(SpamInterface):
    """
    ä»¥è¡Œä¸ºå•ä½åˆ¤æ–­æ˜¯å¦ä¸ºå¹¿å‘Š
    """

    def __init__(self, rule_list):
        self.rule_list = rule_list

    def predict(self, text, params=None):
        sub_lines = text.split(u'\n')
        sub_lines = [item.strip() for item in sub_lines if item.strip()]
        for line in sub_lines:
            for rule in self.rule_list:
                if rule.predict(line):
                    return True
        return False


class AdsSpecialRule(SpamInterface):
    """
    ç‰¹åˆ«è§„åˆ™ï¼Œåªé’ˆå¯¹å‡ ä¸ªç‰¹æ®Šå­—ç¬¦
    æ”¾ä¸€äº›ä¸æˆç†Ÿçš„è§„åˆ™ï¼ŒåæœŸæœ‰å¾ˆå¤§æ¦‚ç‡è¦è°ƒæ•´çš„
    """
    SPECIAL_CHAR = [u'ğŸ’°', u'ğŸ’µ', u'$']

    def predict(self, text, params=None):
        for item in self.SPECIAL_CHAR:
            if item in text:
                return True

        # æ ¼å¼ä¸å…¨
        if u'ã€' in text and u'ã€‘' not in text:
            return True
        if u'ã€' not in text and u'ã€‘' in text:
            return True

        return False


class AdsPrefixRule(SpamInterface):
    """
    åŸºäºæ–‡æœ¬å‰ç¼€åˆ¤æ–­
    """

    def __init__(self):
        self.base_rule = SpamPrefixRule()

    def predict(self, text, params=None):
        lines = params
        if len(lines) < 0:
            return False
        # ç¬¬ä¸€è¡Œ
        if self.base_rule.predict(lines[0].strip()):
            return True

        # ç¬¬äºŒè¡Œ
        if self.base_rule.predict(lines[-1].strip()):
            return True

        return False


class SpamPrefixRule(SpamInterface):
    """
    åŸºäºæ–‡æœ¬å‰ç¼€åˆ¤æ–­
    """
    def __init__(self, user_re=False):
        self.word_set = set()
        self.rule_pattern = None

        self._load()

        self.use_re = user_re

    def _load(self):
        # 1.åŠ è½½å¹¿å‘Šè¯
        self.word_set = OrdinaryWays.get_clean('weibo_ads_prefix_word')

        rule_str = u"^" + u"(" + u'|'.join(self.word_set) + u')'
        self.rule_pattern = re.compile(rule_str, re.I | re.S)

    def _do_by_re(self, text, params=None):
        result = self.rule_pattern.search(text)
        if result and result.group() is not None:
            return True

        return False

    def _do(self, text, params=None):
        for word in self.word_set:
            if text.startswith(word):
                return True

        return False

    def predict(self, text, params=None):
        if self.use_re:
            return self._do_by_re(text)
        return self._do(text)


class AdsSuffixRule(SpamInterface):
    """
    åŸºäºæ–‡æœ¬åç¼€åˆ¤æ–­
    """

    def __init__(self):
        self.base_rule = SpamSuffixRule()

    def predict(self, text, params=None):
        """
        è¯¥æ–‡æœ¬æ˜¯å¦ä¸ºå®¢è§‚æè¿°ç±»
        :param text:
        :param params:
        :return:
        """
        lines = params
        if len(lines) < 0:
            return False

        # ç¬¬ä¸€è¡Œ
        if self.base_rule.predict(lines[0]):
            return True

        # æœ€åä¸€è¡Œ
        if self.base_rule.predict(lines[-1]):
            return True

        return False


class SpamSuffixRule(SpamInterface):
    """
    åŸºäºæ–‡æœ¬å‰ç¼€åˆ¤æ–­
    """

    def __init__(self, use_re=False):
        self.word_set = set()
        self.rule_pattern = None

        self._load()

        self.use_re = use_re

    def _load(self):
        self.word_set = OrdinaryWays.get_clean('weibo_ads_suffix_word')

        rule_str = u"(" + u'|'.join(self.word_set) + u')' + u"$"
        self.rule_pattern = re.compile(rule_str, re.I | re.S)

    def _do_by_re(self, text, params=None):
        result = self.rule_pattern.search(text)
        if result and result.group() is not None:
            return True

        return False

    def _do(self, text, params=None):
        for word in self.word_set:
            if text.endswith(word):
                return True

        return False

    def predict(self, text, params=None):
        if self.use_re:
            return self._do_by_re(text)
        return self._do(text)


class WeiboAdsRuleModel(RowInterface, CleanInterface):
    def __init__(self, **params):
        super(WeiboAdsRuleModel, self).__init__(CleanFlag.NO)

        self.rule_pattern = SpamPatternRule()
        self.rule_hastag = SpamHastagRule([ItemPriceRule(), ItemNumRule()])
        self.rule_word = SpamWordRule()
        self.rule_delimiter = AdsDelimiter(ItemPriceRule())

        sub_rule_list = list()
        sub_rule_list.append(self.rule_word)
        sub_rule_list.append(self.rule_pattern)
        sub_rule_list.append(self.rule_delimiter)
        sub_rule_list.append(self.rule_hastag)

        self.rule_list = list()
        self.rule_list.append(AdsLineRule(sub_rule_list))
        self.rule_list.append(AdsSpecialRule())
        self.rule_list.append(AdsPrefixRule())
        self.rule_list.append(AdsSuffixRule())

    def _clean(self, text):
        tmp_text = text
        # å»æ‰ç‰¹æ®Šçš„ç»“å°¾ç¬¦(htmlæ ¼å¼ä¸­åŒ…å«)
        ch = chr(8203)
        tmp_text = tmp_text.replace(ch, u'')
        tmp_text = tmp_text.replace(u'\r\n', u'\n')

        # TODO å»æ‰å¤šä½™çš„é—®å·,æœ‰å¥½äº›é—®å·æ˜¯è§£ææˆ–æŠ“å–æ—¶äº§ç”Ÿçš„ï¼Œä¸æ˜¯åŸæ–‡è‡ªå¸¦çš„
        tmp_text = tmp_text.replace(u'?', u'')

        return tmp_text

    def process(self, data, **params):
        """
        é¢„æµ‹
        :param data: æ–‡æœ¬
        :param params: å‚æ•°
        :return:
        """
        clean_text = str(data).lower()
        lines = clean_text.split(u'\n')
        lines = [line.strip() for line in lines]
        for rule in self.rule_list:
            if rule.predict(clean_text, lines):
                return CleanFlag.YES

        return CleanFlag.NO


def run_spam():
    sub_model_ads = WeiboAdsRuleModel()

    content = u'ã€19.9ã€‘å®ä¸½åº·ç¾ æ ¸æ¡ƒé»‘èŠéº»é»‘è±†ä»£é¤ç²‰'
    # content = u'æ¡ƒé»‘èŠéº»é»‘è±†ä»£é¤ç²‰'
    channel = u"weibo"
    result = sub_model_ads.process(content)
    print(result)


if __name__ == '__main__':
    run_spam()


